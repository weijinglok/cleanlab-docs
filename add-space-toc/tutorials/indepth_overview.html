<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Computing Out-of-Sample Predicted Probabilities with Cross-Validation" href="pred_probs_cross_val.html" /><link rel="prev" title="Audio Classification with SpeechBrain and Cleanlab" href="audio.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/a4483476d449f2f05a4c7cde329e72358099cc07/cleanlab/cleanlab_favicon.svg"/><meta name="generator" content="sphinx-4.4.0, furo 2022.02.23"/>
        <title>Cleanlab 2.0: The Workflows of Data-centric AI - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=3c656993158f05539f962c5cea52a5e6c184bb8c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a style="padding-bottom: 0px;" class="sidebar-brand centered" href="../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo" />
    </div>
    
    <span style="margin-bottom:0px" class="sidebar-brand-text">
        cleanlab
    </span>
    
</a>

<div class="centered">
    <a style="margin-top: 6px;" class="github-button" href="https://github.com/cleanlab/cleanlab" data-size="large" data-show-count="true"
    aria-label="Star cleanlab/cleanlab on GitHub">Star</a>
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="image.html">Image Classification with PyTorch and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="text.html">Text Classification with TensorFlow, Keras, and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="tabular.html">Classification with Tabular Data using Scikit-Learn and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio.html">Audio Classification with SpeechBrain and Cleanlab</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Cleanlab 2.0: The Workflows of Data-centric AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_probs_cross_val.html">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/count.html">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/dataset.html">dataset</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/benchmarking/index.html">benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/benchmarking/noise_generation.html">noise_generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/experimental/index.html">experimental</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/fasttext.html">fasttext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/mnist_pytorch.html">mnist_pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/coteaching.html">coteaching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/cifar_cnn.html">cifar_cnn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/label_quality_utils.html">label_quality_utils</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migrating/migrate_v2.html">Migrating to v2.0</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/cleanlab-docs/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/cleanlab-docs/master/"
                >developer</a
            >
        </li>
    </ul>
</div>

<br>
<br>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number)) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">add-space-toc</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }

    .output_area {
        max-height: 300px;
        overflow: auto;
    }
</style>
<script type="text/javascript">
    window.addEventListener('load', () => {
        const h1_element = document.getElementsByTagName("h1");
        h1_element[0].insertAdjacentHTML("afterend", `
        <p>
            <a style="background-color:white;color:black;padding:4px 12px;text-decoration:none;display:inline-block;border-radius:8px;box-shadow:0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 3px 10px 0 rgba(0, 0, 0, 0.19)" href="https://colab.research.google.com/github/weijinglok/cleanlab-docs/blob/master/add-space-toc/tutorials/indepth_overview.ipynb" target="_blank">
            <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="Google Colab Logo" style="width:40px;height:40px;vertical-align:middle">
            <span style="vertical-align:middle">Run in Google Colab</span>
            </a>
        </p>
        `);
    })

</script><div class="section" id="Cleanlab-2.0:-The-Workflows-of-Data-centric-AI">
<h1>Cleanlab 2.0: The Workflows of Data-centric AI<a class="headerlink" href="#Cleanlab-2.0:-The-Workflows-of-Data-centric-AI" title="Permalink to this headline">#</a></h1>
<p>In this tutorial, you will learn how to easily incorporate the new and improved <a class="reference external" href="https://github.com/cleanlab/cleanlab">cleanlab 2.0</a> into your ML development workflows to:</p>
<ul class="simple">
<li><p>Automatically find label issues lurking in your data.</p></li>
<li><p>Score the label quality of every example in your dataset.</p></li>
<li><p>Train robust models in the presence of label issues.</p></li>
<li><p>Identify overlapping classes that you can merge to make the learning task less ambiguous.</p></li>
<li><p>Generate an overall label health score to track improvements in your labels as you clean your datasets over time.</p></li>
</ul>
<p>This tutorial provides an in-depth survey of many possible different ways that cleanlab can be utilized for Data-Centric AI. If you have a different use-case in mind that is not supported, please <a class="reference external" href="https://github.com/cleanlab/cleanlab/issues">tell us about it</a>!</p>
<p><strong>cleanlab is grounded in theory and science</strong>. Learn more: <a class="reference external" href="https://cleanlab.ai/research">Research Publications</a> | <a class="reference external" href="https://labelerrors.com/">Label Errors found by cleanlab</a> | <a class="reference external" href="https://github.com/cleanlab/examples">Examples using cleanlab</a></p>
<div class="section" id="Install-dependencies-and-import-them">
<h2>Install dependencies and import them<a class="headerlink" href="#Install-dependencies-and-import-them" title="Permalink to this headline">#</a></h2>
<p>You can use pip to install all packages required for this tutorial as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>!pip install sklearn matplotlib
!pip install cleanlab
# Make sure to install the version corresponding to this tutorial
# E.g. if viewing master branch documentation:
#     !pip install git+https://github.com/cleanlab/cleanlab.git
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cleanlab</span>
<span class="kn">from</span> <span class="nn">cleanlab.classification</span> <span class="kn">import</span> <span class="n">CleanLearning</span>
<span class="kn">from</span> <span class="nn">cleanlab.benchmarking</span> <span class="kn">import</span> <span class="n">noise_generation</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Create-the-data-used-for-this-tutorial-(can-skip-these-details)">
<h2>Create the data used for this tutorial (can skip these details)<a class="headerlink" href="#Create-the-data-used-for-this-tutorial-(can-skip-these-details)" title="Permalink to this headline">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span>
    <span class="n">means</span><span class="o">=</span><span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]],</span>
    <span class="n">covs</span><span class="o">=</span><span class="p">[</span>
        <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="n">avg_trace</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>  <span class="c1"># set to None for non-reproducible randomness</span>
<span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>  <span class="c1"># number of classes</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">means</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">covs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">means</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">covs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">idx</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])]))</span>
        <span class="n">test_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">idx</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])]))</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

    <span class="c1"># Compute p(y=k) the prior distribution over true labels.</span>
    <span class="n">py_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

    <span class="n">noise_matrix_true</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noise_matrix_from_trace</span><span class="p">(</span>
        <span class="n">K</span><span class="p">,</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">avg_trace</span> <span class="o">*</span> <span class="n">K</span><span class="p">,</span>
        <span class="n">py</span><span class="o">=</span><span class="n">py_true</span><span class="p">,</span>
        <span class="n">valid_noise_matrix</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Generate our noisy labels using the noise_marix.</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noisy_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">noise_matrix_true</span><span class="p">)</span>
    <span class="n">s_test</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noisy_labels</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">noise_matrix_true</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>  <span class="c1"># Prior distribution over noisy labels</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">"data"</span><span class="p">:</span> <span class="n">X_train</span><span class="p">,</span>
        <span class="s2">"true_labels"</span><span class="p">:</span> <span class="n">y_train</span><span class="p">,</span>  <span class="c1"># You never get to see these perfect labels.</span>
        <span class="s2">"labels"</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>  <span class="c1"># Instead, you have these labels, which have some errors.</span>
        <span class="s2">"test_data"</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span>
        <span class="s2">"test_labels"</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>  <span class="c1"># Perfect labels used for "true" measure of model's performance during deployment.</span>
        <span class="s2">"noisy_test_labels"</span><span class="p">:</span> <span class="n">s_test</span><span class="p">,</span>  <span class="c1"># With IID train/test split, you'd have these labels, which also have some errors.</span>
        <span class="s2">"ps"</span><span class="p">:</span> <span class="n">ps</span><span class="p">,</span>
        <span class="s2">"py_true"</span><span class="p">:</span> <span class="n">py_true</span><span class="p">,</span>
        <span class="s2">"noise_matrix_true"</span><span class="p">:</span> <span class="n">noise_matrix_true</span><span class="p">,</span>
        <span class="s2">"class_names"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"purple"</span><span class="p">,</span> <span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"seafoam green"</span><span class="p">,</span> <span class="s2">"yellow"</span><span class="p">],</span>
    <span class="p">}</span>


<span class="n">data_dict</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">()</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>  <span class="c1"># Map data_dict to variables in namespace</span>
    <span class="n">exec</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s2">"=val"</span><span class="p">)</span>

<span class="c1"># Display dataset visually using matplotlib</span>
<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">circles</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s2">"o"</span><span class="p">,</span>
            <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">"none"</span><span class="p">,</span>
            <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
            <span class="n">markeredgewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
        <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>

<span class="n">true_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">true_labels</span> <span class="o">!=</span> <span class="n">labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">true_errors</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"A realistic, messy dataset with 4 classes"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_6_0.png" src="../_images/tutorials_indepth_overview_6_0.png"/>
</div>
</div>
<p>The figure above represents a toy dataset we’ll use to demonstrate various cleanlab functionality. In this data, the features <em>X</em> are 2-dimensional and examples are colored according to their <em>given</em> label above.</p>
<p>Like <a class="reference external" href="https://labelerrors.com/">many real-world datasets</a>, the given label happens to be incorrect for some of the examples (<strong>circled in red</strong>) in this dataset!</p>
</div>
<div class="section" id="Workflow-1:-Use-CleanLearning()-for-everything">
<h2><strong>Workflow 1:</strong> Use CleanLearning() for everything<a class="headerlink" href="#Workflow-1:-Use-CleanLearning()-for-everything" title="Permalink to this headline">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># CleanLearning: Machine Learning with cleaned data (given messy, real-world data)</span>
<span class="n">cl</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Fit model to messy, real-world data, automatically training on cleaned data.</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># See the label quality for every example, which data has issues, and more.</span>
<span class="n">cl</span><span class="o">.</span><span class="n">get_label_issues</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<div class="table-wrapper"><table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>is_label_issue</th>
<th>label_quality</th>
<th>given_label</th>
<th>predicted_label</th>
<th>sample_weight</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>False</td>
<td>0.695174</td>
<td>0</td>
<td>0</td>
<td>1.323529</td>
</tr>
<tr>
<th>1</th>
<td>False</td>
<td>0.522929</td>
<td>0</td>
<td>0</td>
<td>1.323529</td>
</tr>
<tr>
<th>2</th>
<td>True</td>
<td>0.013722</td>
<td>3</td>
<td>0</td>
<td>0.000000</td>
</tr>
<tr>
<th>3</th>
<td>False</td>
<td>0.675606</td>
<td>0</td>
<td>0</td>
<td>1.323529</td>
</tr>
<tr>
<th>4</th>
<td>False</td>
<td>0.646438</td>
<td>0</td>
<td>0</td>
<td>1.323529</td>
</tr>
</tbody>
</table></div>
</div></div>
</div>
<div class="section" id="Clean-Learning-=-Machine-Learning-with-cleaned-data">
<h3>Clean Learning = Machine Learning with cleaned data<a class="headerlink" href="#Clean-Learning-=-Machine-Learning-with-cleaned-data" title="Permalink to this headline">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For comparison, this is how you would have trained your model normally (without Cleanlab)</span>
<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy using yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># But CleanLearning can do anything yourFavoriteModel can do, but enhanced.</span>
<span class="c1"># For example, CleanLearning gives you predictions (just like yourFavoriteModel)</span>
<span class="c1"># but the magic is that CleanLearning was trained as if your data did not have label errors.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">cl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Accuracy using yourFavoriteModel: 83%
Accuracy using yourFavoriteModel (+ CleanLearning): 86%
</pre></div></div>
</div>
<p>Note! <em>Accuracy</em> refers to the accuracy with respect to the <em>true</em> error-free labels of a test set., i.e. what we actually care about in practice because that’s what real-world model performance is based on. If you don’t have a clean test set, you can use cleanlab to make one :)</p>
</div>
</div>
<div class="section" id="Workflow-2:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code">
<h2><strong>Workflow 2:</strong> Use CleanLearning to find_label_issues in one line of code<a class="headerlink" href="#Workflow-2:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code" title="Permalink to this headline">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># One line of code. Literally.</span>
<span class="n">issues</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="n">issues</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<div class="table-wrapper"><table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>is_label_issue</th>
<th>label_quality</th>
<th>given_label</th>
<th>predicted_label</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>False</td>
<td>0.695174</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>1</th>
<td>False</td>
<td>0.522929</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>2</th>
<td>True</td>
<td>0.013722</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<th>3</th>
<td>False</td>
<td>0.675606</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<th>4</th>
<td>False</td>
<td>0.646438</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table></div>
</div></div>
</div>
<div class="section" id="Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">
<h3>Visualize the twenty examples with lowest label quality to see if Cleanlab works.<a class="headerlink" href="#Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works." title="Permalink to this headline">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lowest_quality_labels</span> <span class="o">=</span> <span class="n">issues</span><span class="p">[</span><span class="s2">"label_quality"</span><span class="p">]</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="mi">20</span><span class="p">]</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">lowest_quality_labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"The 20 lowest label quality examples"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_16_0.png" src="../_images/tutorials_indepth_overview_16_0.png"/>
</div>
</div>
<p>Above, the top 20 label issues circled in red are found automatically using cleanlab (no true labels given).</p>
<p>If you’ve already computed the label issues using <code class="docutils literal notranslate"><span class="pre">CleanLearning</span></code>, you can pass them into <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and it will train <strong>much</strong> faster (skips label-issue identification step).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CleanLearning can train faster if issues are provided at fitting time.</span>
<span class="n">cl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">label_issues</span><span class="o">=</span><span class="n">issues</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CleanLearning(clf=LogisticRegression(random_state=0),
              find_label_issues_kwargs={'min_examples_per_class': 10}, seed=0)
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Workflow-3:-Use-cleanlab-to-find-dataset-level-and-class-level-issues">
<h2><strong>Workflow 3:</strong> Use cleanlab to find dataset-level and class-level issues<a class="headerlink" href="#Workflow-3:-Use-cleanlab-to-find-dataset-level-and-class-level-issues" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Did you notice that the yellow and seafoam green class above are overlapping?</p></li>
<li><p>How can a model ever know (or learn) what’s ground truth inside the yellow distribution?</p></li>
<li><p>If these two classes were merged, the model can learn more accurately from 3 classes (versus 4).</p></li>
</ul>
<p>cleanlab automatically finds data-set level issues like this, in one line of code. Check this out!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleanlab</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">find_overlapping_classes</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">confident_joint</span><span class="o">=</span><span class="n">cl</span><span class="o">.</span><span class="n">confident_joint</span><span class="p">,</span>  <span class="c1"># cleanlab uses the confident_joint internally to quantify label noise (see cleanlab.count.compute_confident_joint)</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<div class="table-wrapper"><table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>Class Name A</th>
<th>Class Name B</th>
<th>Class Index A</th>
<th>Class Index B</th>
<th>Num Overlapping Examples</th>
<th>Joint Probability</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>seafoam green</td>
<td>yellow</td>
<td>2</td>
<td>3</td>
<td>26</td>
<td>0.104</td>
</tr>
<tr>
<th>1</th>
<td>purple</td>
<td>seafoam green</td>
<td>0</td>
<td>2</td>
<td>23</td>
<td>0.092</td>
</tr>
<tr>
<th>2</th>
<td>purple</td>
<td>yellow</td>
<td>0</td>
<td>3</td>
<td>10</td>
<td>0.040</td>
</tr>
<tr>
<th>3</th>
<td>blue</td>
<td>seafoam green</td>
<td>1</td>
<td>2</td>
<td>6</td>
<td>0.024</td>
</tr>
<tr>
<th>4</th>
<td>purple</td>
<td>blue</td>
<td>0</td>
<td>1</td>
<td>5</td>
<td>0.020</td>
</tr>
<tr>
<th>5</th>
<td>blue</td>
<td>yellow</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>0.004</td>
</tr>
</tbody>
</table></div>
</div></div>
</div>
<p>Do the results surprise you? Did you expect the purple and seafoam green to also have so much overlap?</p>
<p>There are two things being happening here:</p>
<ol class="arabic simple">
<li><p><strong>Distribution Overlap</strong>: The green distribution has huge variance and overlaps with other distributions.</p>
<ul class="simple">
<li><p>Cleanlab handles this for you: read the theory behind cleanlab for overlapping classes here: <a class="reference external" href="https://arxiv.org/abs/1705.01936">https://arxiv.org/abs/1705.01936</a></p></li>
</ul>
</li>
<li><p><strong>Label Issues</strong>: A ton of examples (which actually belong to the purple class) have been mislabeled as “green” in our dataset.</p></li>
</ol>
<div class="section" id="Now,-let’s-see-what-happens-if-we-merge-classes-“seafoam-green”-and-“yellow”">
<h3>Now, let’s see what happens if we merge classes “seafoam green” and “yellow”<a class="headerlink" href="#Now,-let’s-see-what-happens-if-we-merge-classes-“seafoam-green”-and-“yellow”" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>the top two classes found automatically by <code class="docutils literal notranslate"><span class="pre">cleanlab.dataset.find_overlapping_classes()</span></code></p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yourFavoriteModel1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[Original classes] Accuracy of yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">merged_labels</span><span class="p">,</span> <span class="n">merged_test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

<span class="c1"># Merge classes: map all yellow-labeled examples to seafoam green</span>
<span class="n">merged_labels</span><span class="p">[</span><span class="n">merged_labels</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">merged_test_labels</span><span class="p">[</span><span class="n">merged_test_labels</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Re-run our comparison. Re-run your model on the newly labeled dataset.</span>
<span class="n">yourFavoriteModel2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">merged_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[Modified classes] Accuracy of yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">merged_test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Re-run CleanLearning as well.</span>
<span class="n">yourFavoriteModel3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">cl3</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">cl3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">merged_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[Modified classes] Accuracy of yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">cl3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">merged_test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[Original classes] Accuracy of yourFavoriteModel: 83%
[Modified classes] Accuracy of yourFavoriteModel: 94%
[Modified classes] Accuracy of yourFavoriteModel (+ CleanLearning): 96%
</pre></div></div>
</div>
<p>While on one hand that’s a huge improvement, it’s important to remember that choosing among three classes is an easier task than choosing among four classes, so it’s not fair to directly compare these numbers.</p>
<p>Instead, the big takeaway is… if you get to choose your classes, combining overlapping classes can make the learning task easier for your model. But if you have lots of classes, how do you know which ones to merge?? That’s when you use <code class="docutils literal notranslate"><span class="pre">cleanlab.dataset.find_overlapping_classes</span></code>.</p>
</div>
</div>
<div class="section" id="Workflow-4:-Clean-your-test-set-too-if-you’re-doing-ML-with-noisy-labels!">
<h2><strong>Workflow 4:</strong> Clean your test set too if you’re doing ML with noisy labels!<a class="headerlink" href="#Workflow-4:-Clean-your-test-set-too-if-you’re-doing-ML-with-noisy-labels!" title="Permalink to this headline">#</a></h2>
<p>If your test and training data were randomly split (IID), then be aware that your test labels are likely noisy too! It is thus important to fix label issues in them before we can trust measures like test accuracy. * More about what can go wrong if you don’t use a clean test set <a class="reference external" href="https://arxiv.org/abs/2103.14749">in this paper</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Fit your model on noisily labeled train data</span>
<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Get predicted probabilities for test data (these are out-of-sample)</span>
<span class="n">my_test_pred_probs</span> <span class="o">=</span> <span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">my_test_preds</span> <span class="o">=</span> <span class="n">my_test_pred_probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># predicted labels</span>

<span class="c1"># Find label issues in the test data</span>
<span class="n">issues_test</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">noisy_test_labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">my_test_pred_probs</span><span class="p">)</span>

<span class="c1"># You should inspect issues_test and fix issues to ensure high-quality test data labels.</span>
<span class="n">corrected_test_labels</span> <span class="o">=</span> <span class="n">test_labels</span>  <span class="c1"># Here we'll pretend you have done this perfectly :)</span>

<span class="c1"># Fit more robust version of model on noisily labeled training data</span>
<span class="n">cl</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">cl_test_preds</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" Noisy Test Accuracy (on given test labels) using yourFavoriteModel: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">noisy_test_labels</span><span class="p">,</span> <span class="n">my_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" Noisy Test Accuracy (on given test labels) using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">noisy_test_labels</span><span class="p">,</span> <span class="n">cl_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actual Test Accuracy (on corrected test labels) using yourFavoriteModel: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">corrected_test_labels</span><span class="p">,</span> <span class="n">my_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actual Test Accuracy (on corrected test labels) using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">corrected_test_labels</span><span class="p">,</span> <span class="n">cl_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 Noisy Test Accuracy (on given test labels) using yourFavoriteModel: 69%
 Noisy Test Accuracy (on given test labels) using yourFavoriteModel (+ CleanLearning): 71%
Actual Test Accuracy (on corrected test labels) using yourFavoriteModel: 83%
Actual Test Accuracy (on corrected test labels) using yourFavoriteModel (+ CleanLearning): 86%
</pre></div></div>
</div>
</div>
<div class="section" id="Workflow-5:-One-score-to-rule-them-all-–-use-cleanlab’s-overall-dataset-health-score">
<h2><strong>Workflow 5:</strong> One score to rule them all – use cleanlab’s overall dataset health score<a class="headerlink" href="#Workflow-5:-One-score-to-rule-them-all-–-use-cleanlab’s-overall-dataset-health-score" title="Permalink to this headline">#</a></h2>
<p>This score can be fairly compared across datasets or across versions of a dataset to track overall dataset quality (a.k.a. <em>dataset health</em>) over time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># One line of code.</span>
<span class="n">health</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">overall_label_health_score</span><span class="p">(</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">confident_joint</span><span class="o">=</span><span class="n">cl</span><span class="o">.</span><span class="n">confident_joint</span>
    <span class="c1"># cleanlab uses the confident_joint internally to quantify label noise (see cleanlab.count.compute_confident_joint)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 * Overall, about 28% (71 of the 250) labels in your dataset have potential issues.
 ** The overall label health score for this dataset is: 0.72.
</pre></div></div>
</div>
<div class="section" id="How-accurate-is-this-dataset-health-score?">
<h3>How accurate is this dataset health score?<a class="headerlink" href="#How-accurate-is-this-dataset-health-score?" title="Permalink to this headline">#</a></h3>
<p>Because we know the true labels (we created this toy dataset), we can compare with ground truth.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="n">true_labels</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Percentage of label issues guessed by cleanlab </span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">health</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Percentage of (ground truth) label errors): </span><span class="si">{</span><span class="n">label_acc</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">offset</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">label_acc</span><span class="p">)</span> <span class="o">-</span> <span class="n">health</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Question: cleanlab seems to be overestimating."</span>
    <span class="sa">f</span><span class="s2">" How do we account for this </span><span class="si">{</span><span class="n">offset</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2"> difference?"</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">"Answer: Data points that fall in between two overlapping distributions are often "</span>
    <span class="s2">"impossible to label and are counted as issues."</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Percentage of label issues guessed by cleanlab 28%
Percentage of (ground truth) label errors): 20%

Question: cleanlab seems to be overestimating. How do we account for this 8% difference?
Answer: Data points that fall in between two overlapping distributions are often impossible to label and are counted as issues.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Workflow(s)-6:-Use-count,-rank,-filter-modules-directly">
<h2><strong>Workflow(s) 6:</strong> Use count, rank, filter modules directly<a class="headerlink" href="#Workflow(s)-6:-Use-count,-rank,-filter-modules-directly" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Using these modules directly is intended for more experienced cleanlab users. But once you understand how they work, you can create numerous powerful workflows.</p></li>
<li><p>For these workflows, you <strong>always</strong> need two things:</p>
<ol class="arabic simple">
<li><p>out-of-sample predicted probabilities (e.g. computed via cross-validation)</p></li>
<li><p>labels (can contain label errors and various issues)</p></li>
</ol>
</li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_cv_predicted_probabilities</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"pred_probs is a </span><span class="si">{</span><span class="n">pred_probs</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> matrix of predicted probabilites"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
pred_probs is a (250, 4) matrix of predicted probabilites
</pre></div></div>
</div>
<div class="section" id="Workflow-6.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-…)">
<h3><strong>Workflow 6.1 (count)</strong>: Fully characterize label noise (noise matrix, joint, prior of true labels, …)<a class="headerlink" href="#Workflow-6.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-…)" title="Permalink to this headline">#</a></h3>
<p>Now that we have <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code>, advanced users can compute everything in <code class="docutils literal notranslate"><span class="pre">cleanlab.count</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">py:</span> <span class="pre">prob(true_label=k)</span></code></p>
<ul>
<li><p>For all classes K, this is the distribution over the actual true labels (which cleanlab can estimate for you even though you don’t have the true labels).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">noise_matrix:</span> <span class="pre">p(noisy|true)</span></code></p>
<ul>
<li><p>This describes how errors were introduced into your labels. It’s a conditional probability matrix with the probability of flipping from the true class to every other class for the given label.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse</span> <span class="pre">noise</span> <span class="pre">matrix:</span> <span class="pre">p(true|noisy)</span></code></p>
<ul>
<li><p>This tells you the probability, for every class, that the true label is actually a different class.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">confident_joint</span></code></p>
<ul>
<li><p>This is an unnormalized (count-based) estimate of the number of examples in our dataset with each possible (true label, given label) pairing.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">joint:</span> <span class="pre">p(true</span> <span class="pre">label,</span> <span class="pre">noisy</span> <span class="pre">label)</span></code></p>
<ul>
<li><p>The joint distribution of noisy (given) and true labels is the most useful of all these statistics. From it, you can compute every other statistic listed above. One entry from this matrix can be interpreted as: “The proportion of examples in our dataset whose true label is <em>i</em> and given label is <em>j</em>”.</p></li>
</ul>
</li>
</ul>
<p>These five tools fully characterize class-conditional label noise in a dataset.</p>
<div class="section" id="Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:">
<h4>Use cleanlab to estimate and visualize the joint distribution of label noise and noise matrix of label flipping rates:<a class="headerlink" href="#Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:" title="Permalink to this headline">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">py</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="p">,</span> <span class="n">inverse_noise_matrix</span><span class="p">,</span> <span class="n">confident_joint</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_py_and_noise_matrices_from_probabilities</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>

<span class="c1"># Note: you can also combine the above two lines of code into a single line of code like this</span>
<span class="p">(</span>
    <span class="n">py</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="p">,</span> <span class="n">inverse_noise_matrix</span><span class="p">,</span> <span class="n">confident_joint</span><span class="p">,</span> <span class="n">pred_probs</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_py_noise_matrices_and_cv_pred_proba</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>

<span class="c1"># Get the joint distribution of noisy and true labels from the confident joint</span>
<span class="c1"># This is the most powerful statistic in machine learning with noisy labels.</span>
<span class="n">joint</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_joint</span><span class="p">(</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">,</span> <span class="n">confident_joint</span><span class="o">=</span><span class="n">confident_joint</span>
<span class="p">)</span>

<span class="c1"># Pretty print the joint distribution and noise matrix</span>
<span class="n">cleanlab</span><span class="o">.</span><span class="n">internal</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">print_joint_matrix</span><span class="p">(</span><span class="n">joint</span><span class="p">)</span>
<span class="n">cleanlab</span><span class="o">.</span><span class="n">internal</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">print_noise_matrix</span><span class="p">(</span><span class="n">noise_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

 Joint Label Noise Distribution Matrix P(given_label, true_label) of shape (4, 4)
 p(s,y) y=0     y=1     y=2     y=3
        ---     ---     ---     ---
s=0 |   0.27    0.0     0.03    0.03
s=1 |   0.02    0.18    0.01    0.0
s=2 |   0.06    0.01    0.12    0.06
s=3 |   0.01    0.0     0.05    0.14
        Trace(matrix) = 0.72


 Noise Matrix (aka Noisy Channel) P(given_label|true_label) of shape (4, 4)
 p(s|y) y=0     y=1     y=2     y=3
        ---     ---     ---     ---
s=0 |   0.76    0.0     0.15    0.14
s=1 |   0.06    0.92    0.06    0.0
s=2 |   0.17    0.06    0.57    0.25
s=3 |   0.02    0.02    0.22    0.61
        Trace(matrix) = 2.86

</pre></div></div>
</div>
<p>In some applications, you may have a priori knowledge regarding some of these quantities. In this case, you can pass them directly into cleanlab which may be able to leverage this information to better identify label issues.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cl3</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">cl3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="o">=</span><span class="n">noise_matrix_true</span><span class="p">)</span>  <span class="c1"># CleanLearning with a prioiri known noise_matrix</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Workflow-6.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code">
<h3><strong>Workflow 6.2 (filter):</strong> Find label issues for any dataset and any model in one line of code<a class="headerlink" href="#Workflow-6.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code" title="Permalink to this headline">#</a></h3>
<p>Features of <code class="docutils literal notranslate"><span class="pre">cleanlab.filter.find_label_issues</span></code>: * Versatility – Choose from several <a class="reference external" href="https://arxiv.org/abs/1911.00068">state-of-the-art</a> label-issue detection algorithms using <code class="docutils literal notranslate"><span class="pre">filter_by=</span></code>. * Works with any model by using predicted probabilities (no model needed). * one line of code :)</p>
<p>Remember <code class="docutils literal notranslate"><span class="pre">CleanLearning.find_label_issues</span></code>? It uses this method internally.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get out of sample predicted probabilities via cross-validation.</span>
<span class="c1"># Here we demonstrate the use of sklearn cross_val_predict as another option to get cross-validated predicted probabilities</span>
<span class="n">cv_pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"predict_proba"</span>
<span class="p">)</span>

<span class="c1"># Find label issues</span>
<span class="n">label_issues_indices</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs</span><span class="p">,</span>
    <span class="n">filter_by</span><span class="o">=</span><span class="s2">"both"</span><span class="p">,</span> <span class="c1"># 5 available filter_by options</span>
    <span class="n">return_indices_ranked_by</span><span class="o">=</span><span class="s2">"self_confidence"</span><span class="p">,</span>  <span class="c1"># 3 available label quality scoring options for rank ordering</span>
    <span class="n">rank_by_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"adjust_pred_probs"</span><span class="p">:</span> <span class="kc">True</span>  <span class="c1"># adjust predicted probabilities (see docstring for more details)</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Return dataset indices of examples with label issues</span>
<span class="n">label_issues_indices</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 99,   8,  64,  45,  83, 213, 212, 218, 152, 197, 196, 170, 167,
       214, 164, 198,  21, 191, 107,  16,  51,  63,   2, 175,  10, 121,
       117,  24,  95,  82,  76,  26,  90,  25,  62,  22,  92,  49,  97,
       206,  68, 115,   7,  48,  43, 193, 184, 249, 194, 186, 201, 174,
       188, 163, 150, 190, 169, 151, 168,  54])
</pre></div></div>
</div>
<div class="section" id="Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">
<h4>Again, we can visualize the twenty examples with lowest label quality to see if Cleanlab works.<a class="headerlink" href="#Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works." title="Permalink to this headline">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">label_issues_indices</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Top 20 label issues found by cleanlab.filter.find_label_issues()"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_40_0.png" src="../_images/tutorials_indepth_overview_40_0.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="Workflow-6.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter.">
<h3>Workflow 6.2 supports lots of methods to <code class="docutils literal notranslate"><span class="pre">find_label_issues()</span></code> via the <code class="docutils literal notranslate"><span class="pre">filter_by</span></code> parameter.<a class="headerlink" href="#Workflow-6.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter." title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Here, we evaluate precision/recall/f1/accuracy of detecting true label issues for each method.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Get cross-validated predicted probabilities</span>
<span class="c1"># Here we demonstrate the use of sklearn cross_val_predict as another option to get cross-validated predicted probabilities</span>
<span class="n">cv_pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"predict_proba"</span>
<span class="p">)</span>

<span class="c1"># Ground truth label issues to use for evaluating different filter_by options</span>
<span class="n">true_label_issues</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">!=</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Find label issues with different filter_by options</span>
<span class="n">filter_by_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"prune_by_noise_rate"</span><span class="p">,</span>
    <span class="s2">"prune_by_class"</span><span class="p">,</span>
    <span class="s2">"both"</span><span class="p">,</span>
    <span class="s2">"confident_learning"</span><span class="p">,</span>
    <span class="s2">"predicted_neq_given"</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">filter_by</span> <span class="ow">in</span> <span class="n">filter_by_list</span><span class="p">:</span>

    <span class="c1"># Find label issues</span>
    <span class="n">label_issues</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs</span><span class="p">,</span>
        <span class="n">filter_by</span><span class="o">=</span><span class="n">filter_by</span>
    <span class="p">)</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"filter_by algorithm"</span><span class="p">:</span> <span class="n">filter_by</span><span class="p">,</span>
        <span class="s2">"precision"</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
        <span class="s2">"recall"</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
        <span class="s2">"f1"</span><span class="p">:</span> <span class="n">f1</span><span class="p">,</span>
        <span class="s2">"accuracy"</span><span class="p">:</span> <span class="n">acc</span>
    <span class="p">}</span>

    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># summary of results</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">'f1'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<div class="table-wrapper"><table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>filter_by algorithm</th>
<th>precision</th>
<th>recall</th>
<th>f1</th>
<th>accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>prune_by_noise_rate</td>
<td>0.718750</td>
<td>0.92</td>
<td>0.807018</td>
<td>0.912</td>
</tr>
<tr>
<th>2</th>
<td>both</td>
<td>0.733333</td>
<td>0.88</td>
<td>0.800000</td>
<td>0.912</td>
</tr>
<tr>
<th>3</th>
<td>confident_learning</td>
<td>0.721311</td>
<td>0.88</td>
<td>0.792793</td>
<td>0.908</td>
</tr>
<tr>
<th>1</th>
<td>prune_by_class</td>
<td>0.676923</td>
<td>0.88</td>
<td>0.765217</td>
<td>0.892</td>
</tr>
<tr>
<th>4</th>
<td>predicted_neq_given</td>
<td>0.567901</td>
<td>0.92</td>
<td>0.702290</td>
<td>0.844</td>
</tr>
</tbody>
</table></div>
</div></div>
</div>
</div>
<div class="section" id="Workflow-6.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold.">
<h3><strong>Workflow 6.3 (rank):</strong> Automatically rank every example by a unique label quality score. Find errors using <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code> as a threshold.<a class="headerlink" href="#Workflow-6.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold." title="Permalink to this headline">#</a></h3>
<p>cleanlab can analyze every label in a dataset and provide a numerical score gauging its overall quality. Low-quality labels indicate examples that should be more closely inspected, perhaps because their given label is incorrect, or simply because they represent an ambiguous edge-case that’s worth a second look.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimate the number of label issues</span>
<span class="n">label_issues_count</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">num_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs</span>
<span class="p">)</span>

<span class="c1"># Get label quality scores</span>
<span class="n">label_quality_scores</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">"self_confidence"</span>
<span class="p">)</span>

<span class="c1"># Rank-order by label quality scores and get the top estimated number of label issues</span>
<span class="n">label_issues_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">label_quality_scores</span><span class="p">)[:</span><span class="n">label_issues_count</span><span class="p">]</span>

<span class="n">label_issues_indices</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 99,   8,  64, 107,  10,  16,  51,  63, 121, 213, 212, 218, 117,
         2, 152, 197, 196, 170,  45,  24, 167,  83,  95,  82,  76,  26,
        90, 214, 164,  25,  62,  22, 198,  92,  21, 191,  49,  97,  68,
       115,   7,  48,  43, 193, 184, 194, 186, 174, 188, 163, 155, 150,
       190, 169, 156, 151, 168,  54, 172, 176, 157, 173, 158, 165, 171,
       175, 236, 220, 183, 160, 225, 166, 161, 154, 192, 206, 199, 128,
       162, 153,  56, 180,  80,  40, 195,  44, 113,  94,  73, 142, 177,
       249, 185, 187, 135, 182, 226,  74, 201, 203])
</pre></div></div>
</div>
<div class="section" id="Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works.">
<h4>Again, we can visualize the label issues found to see if Cleanlab works.<a class="headerlink" href="#Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works." title="Permalink to this headline">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">label_issues_indices</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">"Top 20 label issues using cleanlab.rank with cleanlab.count.num_label_issues()"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_46_0.png" src="../_images/tutorials_indepth_overview_46_0.png"/>
</div>
</div>
</div>
<div class="section" id="Not-sure-when-to-use-Workflow-6.2-or-6.3-to-find-label-issues?">
<h4>Not sure when to use Workflow 6.2 or 6.3 to find label issues?<a class="headerlink" href="#Not-sure-when-to-use-Workflow-6.2-or-6.3-to-find-label-issues?" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Workflow 6.2 is the easiest to use as its just one line of code.</p></li>
<li><p>Workflow 6.3 is modular and extensible. As we add more label and data quality scoring functions in <code class="docutils literal notranslate"><span class="pre">cleanlab.rank</span></code>, Workflow 6.3 will always work.</p></li>
<li><p>Workflow 6.3 is also for users who have a custom way to rank their data by label quality, and they just need to know what the cut-off is, found via <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code>.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="Workflow-7:-Ensembling-label-quality-scores-from-multiple-predictors">
<h2><strong>Workflow 7:</strong> Ensembling label quality scores from multiple predictors<a class="headerlink" href="#Workflow-7:-Ensembling-label-quality-scores-from-multiple-predictors" title="Permalink to this headline">#</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># 3 models in ensemble</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">"l2"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>

<span class="c1"># Get cross-validated predicted probabilities from each model</span>
<span class="n">cv_pred_probs_1</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model1</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"predict_proba"</span>
<span class="p">)</span>
<span class="n">cv_pred_probs_2</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model2</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"predict_proba"</span>
<span class="p">)</span>
<span class="n">cv_pred_probs_3</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model3</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">"predict_proba"</span>
<span class="p">)</span>

<span class="c1"># List of predicted probabilities from each model</span>
<span class="n">pred_probs_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv_pred_probs_1</span><span class="p">,</span> <span class="n">cv_pred_probs_2</span><span class="p">,</span> <span class="n">cv_pred_probs_3</span><span class="p">]</span>

<span class="c1"># Get ensemble label quality scores</span>
<span class="n">label_quality_scores_best</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_ensemble_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs_list</span><span class="o">=</span><span class="n">pred_probs_list</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># Alternative approach: create single ensemble predictor and get its pred_probs</span>
<span class="n">cv_pred_probs_ensemble</span> <span class="o">=</span> <span class="p">(</span><span class="n">cv_pred_probs_1</span> <span class="o">+</span> <span class="n">cv_pred_probs_2</span> <span class="o">+</span> <span class="n">cv_pred_probs_3</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span>  <span class="c1"># uniform aggregation of predictions</span>

<span class="c1"># Use this single set of pred_probs to find label issues</span>
<span class="n">label_quality_scores_better</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs_ensemble</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>While ensembling different models’ label quality scores (<code class="docutils literal notranslate"><span class="pre">label_quality_scores_best</span></code>) will often be superior to getting label quality scores from a single ensemble predictor (<code class="docutils literal notranslate"><span class="pre">label_quality_scores_better</span></code>), both approaches produce significantly better label quality scores than just using the predictions from a single model.</p>
</div>
</div>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          <a class="next-page" href="pred_probs_cross_val.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="audio.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Audio Classification with SpeechBrain and Cleanlab</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Cleanlab 2.0: The Workflows of Data-centric AI</a><ul>
<li><a class="reference internal" href="#Install-dependencies-and-import-them">Install dependencies and import them</a></li>
<li><a class="reference internal" href="#Create-the-data-used-for-this-tutorial-(can-skip-these-details)">Create the data used for this tutorial (can skip these details)</a></li>
<li><a class="reference internal" href="#Workflow-1:-Use-CleanLearning()-for-everything"><strong>Workflow 1:</strong> Use CleanLearning() for everything</a><ul>
<li><a class="reference internal" href="#Clean-Learning-=-Machine-Learning-with-cleaned-data">Clean Learning = Machine Learning with cleaned data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-2:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code"><strong>Workflow 2:</strong> Use CleanLearning to find_label_issues in one line of code</a><ul>
<li><a class="reference internal" href="#Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">Visualize the twenty examples with lowest label quality to see if Cleanlab works.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-3:-Use-cleanlab-to-find-dataset-level-and-class-level-issues"><strong>Workflow 3:</strong> Use cleanlab to find dataset-level and class-level issues</a><ul>
<li><a class="reference internal" href="#Now,-let’s-see-what-happens-if-we-merge-classes-“seafoam-green”-and-“yellow”">Now, let’s see what happens if we merge classes “seafoam green” and “yellow”</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-4:-Clean-your-test-set-too-if-you’re-doing-ML-with-noisy-labels!"><strong>Workflow 4:</strong> Clean your test set too if you’re doing ML with noisy labels!</a></li>
<li><a class="reference internal" href="#Workflow-5:-One-score-to-rule-them-all-–-use-cleanlab’s-overall-dataset-health-score"><strong>Workflow 5:</strong> One score to rule them all – use cleanlab’s overall dataset health score</a><ul>
<li><a class="reference internal" href="#How-accurate-is-this-dataset-health-score?">How accurate is this dataset health score?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow(s)-6:-Use-count,-rank,-filter-modules-directly"><strong>Workflow(s) 6:</strong> Use count, rank, filter modules directly</a><ul>
<li><a class="reference internal" href="#Workflow-6.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-…)"><strong>Workflow 6.1 (count)</strong>: Fully characterize label noise (noise matrix, joint, prior of true labels, …)</a><ul>
<li><a class="reference internal" href="#Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:">Use cleanlab to estimate and visualize the joint distribution of label noise and noise matrix of label flipping rates:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-6.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code"><strong>Workflow 6.2 (filter):</strong> Find label issues for any dataset and any model in one line of code</a><ul>
<li><a class="reference internal" href="#Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">Again, we can visualize the twenty examples with lowest label quality to see if Cleanlab works.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-6.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter.">Workflow 6.2 supports lots of methods to <code class="docutils literal notranslate"><span class="pre">find_label_issues()</span></code> via the <code class="docutils literal notranslate"><span class="pre">filter_by</span></code> parameter.</a></li>
<li><a class="reference internal" href="#Workflow-6.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold."><strong>Workflow 6.3 (rank):</strong> Automatically rank every example by a unique label quality score. Find errors using <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code> as a threshold.</a><ul>
<li><a class="reference internal" href="#Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works.">Again, we can visualize the label issues found to see if Cleanlab works.</a></li>
<li><a class="reference internal" href="#Not-sure-when-to-use-Workflow-6.2-or-6.3-to-find-label-issues?">Not sure when to use Workflow 6.2 or 6.3 to find label issues?</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-7:-Ensembling-label-quality-scores-from-multiple-predictors"><strong>Workflow 7:</strong> Ensembling label quality scores from multiple predictors</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>