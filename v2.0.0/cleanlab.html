<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="CIFAR CNN" href="cleanlab.models.html" /><link rel="prev" title="Audio Classification with Cleanlab and LightGBM" href="notebooks/Audio_Tut.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png"/><meta name="generator" content="sphinx-4.4.0, furo 2022.02.23"/>
        <title>Classification - cleanlab docs</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=3c656993158f05539f962c5cea52a5e6c184bb8c" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">cleanlab docs</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">cleanlab docs</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/Image_Tut.html">Image Classification with Cleanlab, PyTorch &amp; Skorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/Text_Tut.html">Text Classification with Cleanlab, TensorFlow, &amp; SciKeras</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/Tabular_Tut.html">Structured Tabular Data Classification with scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/Audio_Tut.html">Audio Classification with Cleanlab and LightGBM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.latent_estimation">Latent Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.noise_generation">Noise Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.baseline_methods">Baseline Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.coteaching">Co-Teaching</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.latent_algebra">Latent Algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.pruning">Pruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.util">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="#module-cleanlab.polyplex">Polyplex</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="#models">Models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="cleanlab.models.html">CIFAR CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="cleanlab.models.html#module-cleanlab.models.mnist_pytorch">MNIST PyTorch</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
  <p class="caption" role="heading">
    <span class="caption-text">Versions</span>
  </p>
  <ul>
    <li class="toctree-l1">
      <a
        id="version_number"
        class="reference internal"
        href="/cleanlab-docs/stable/index.html"
        >stable</a
      >
    </li>
    <li class="toctree-l1">
      <a id="commit_hash" class="reference internal" href="/cleanlab-docs/master/index.html"
        >developer</a
      >
    </li>
  </ul>
</div>

<script type="text/javascript" src="/cleanlab-docs/versioning.js"></script>

<script type="text/javascript">
  function updateVersionInSidebar() {
    var version_number = Version.version_number;
    var commit_hash = Version.commit_hash;

    document.getElementById("version_number").innerHTML =
      "stable <code class='docutils literal notranslate'><span class='pre'> (" +
      version_number +
      ")</span></code>";
    document.getElementById("commit_hash").innerHTML =
      "master <code class='docutils literal notranslate'><span class='pre'> (" +
      commit_hash.slice(0, 7) +
      "&hellip;)</span></code>";
  };

  updateVersionInSidebar();
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          


<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script type="text/javascript" src="/cleanlab-docs/versioning.js"></script>
<script type="text/javascript">
  function genDocVerWarning() {
    var version_number = Version.version_number;
    var path_arr = window.location.pathname.split("/");

    if (path_arr.includes("master")) {
      document.getElementById("doc_ver_warning").innerHTML = `
      <div class="admonition warning">
      <p class="admonition-title">Warning</p>
      <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/cleanlab-docs/stable/index.html">here</a>.</p>
      </div>
      `;
    } else if (!path_arr.includes(version_number)) {
      document.getElementById("doc_ver_warning").innerHTML =
        `
        <div class="admonition warning">
        <p class="admonition-title">Warning</p>
        <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">v2.0.0</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` +
        version_number +
        `</span></code>), click <a href="/cleanlab-docs/stable/index.html">here</a>.</p>
        </div>
      `;
    } else {
      document.getElementById("doc_ver_warning").remove();
    }
  }

  genDocVerWarning();
</script>

<!-- End of Version Warning Banner -->


<div class="section" id="module-cleanlab.classification">
<span id="classification"></span><h1>Classification<a class="headerlink" href="#module-cleanlab.classification" title="Permalink to this headline">#</a></h1>
<p>cleanlab package for multiclass learning with noisy labels for any model.</p>
<p>The LearningWithNoisyLabels class wraps around an instance of a
classifier class. Your classifier must adhere to the sklearn template,
meaning it must define four functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clf.fit(X,</span> <span class="pre">y,</span> <span class="pre">sample_weight</span> <span class="pre">=</span> <span class="pre">None)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clf.predict_proba(X)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clf.predict(X)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clf.score(X,</span> <span class="pre">y,</span> <span class="pre">sample_weight</span> <span class="pre">=</span> <span class="pre">None)</span></code></p></li>
</ul>
<p>where <code class="docutils literal notranslate"><span class="pre">X</span></code> (of length <em>n</em>) contains the data/examples, <code class="docutils literal notranslate"><span class="pre">y</span></code> (of length <em>n</em>)
contains the contains targets formatted as <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">...,</span> <span class="pre">K-1</span></code>, and
<code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> (of length <em>n</em>) re-weights examples in the loss function while
training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are two new notions of confidence in this package:</p>
<p>1. Confident <strong>examples</strong> – examples we are confident are labeled correctly
We prune everything else. Comptuationally, this means keeping the examples
with high probability of belong to their provided label class.
2. Confident <strong>errors</strong> – examples we are confident are labeled erroneously.
We prune these. Comptuationally, this means pruning the examples with
high probability of belong to a different class.</p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cleanlab.classification</span> <span class="kn">import</span> <span class="n">LearningWithNoisyLabels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span> <span class="k">as</span> <span class="n">LogReg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rp</span> <span class="o">=</span> <span class="n">LearningWithNoisyLabels</span><span class="p">(</span><span class="n">clf</span><span class="o">=</span><span class="n">LogReg</span><span class="p">())</span> <span class="c1"># Pass in any classifier.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_may_have_label_errors</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Estimate the predictions as if you had trained without label errors.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">rp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>The easiest way to use any model (Tensorflow, caffe2, PyTorch, etc.)
with <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is to wrap it in a class that inherits
the <code class="docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="k">class</span> <span class="nc">YourModel</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span> <span class="c1"># Inherits sklearn base classifier</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><cite>s</cite> - denotes <em>noisy labels</em>. This is just dataset labels, maybe with errors.</p></li>
<li><p>Class labels (K classes) must be formatted as natural numbers: 0, 1, .., K-1</p></li>
</ul>
</div>
<p><strong>Classes:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels" title="cleanlab.classification.LearningWithNoisyLabels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LearningWithNoisyLabels</span></code></a>([clf, seed, ...])</p></td>
<td><p>Automated learning with noisy labels using any model.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py class">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cleanlab.classification.</span></span><span class="sig-name descname"><span class="pre">LearningWithNoisyLabels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prune_by_noise_rate'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pulearning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/classification.html#LearningWithNoisyLabels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.base.BaseEstimator</span></code></p>
<p>Automated learning with noisy labels using any model.</p>
<p>Confident Learning is the state-of-the-art (Northcutt et al., 2021) for
weak supervision, finding label errors in datasets, learning with noisy
labels, uncertainty estimation, and more. It works with ANY classifier,
including deep neural networks. See clf parameter.</p>
<p>This subfield of machine learning is referred to as Confident Learning.
Confident Learning also achieves state-of-the-art performance for binary
classification with noisy labels and positive-unlabeled learning
(PU learning) where a subset of positive examples is given and
all other examples are unlabeled and assumed to be negative examples.
Confident Learning works by “learning from confident examples.” Confident
examples are identified as examples with high predicted probability
for their training label.</p>
<p>Given any classifier having the predict_proba() method, an input feature
matrix, X, and a discrete vector of labels, s, which may contain
mislabeling, Confident Learning estimates the classifications that would
be obtained if the hidden, true labels, y, had instead been provided to
the classifier during training. “s” denotes the noisy label instead of
tilde(y), for ASCII encoding reasons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>clf</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> compliant class (e.g. skorch wraps around PyTorch)) – See cleanlab.models for examples of sklearn wrappers around, e.g. PyTorch.
The clf object must have the following three functions defined:
1. clf.predict_proba(X) # Predicted probabilities
2. clf.predict(X) # Predict labels
3. clf.fit(X, y, sample_weight) # Train classifier
Stores the classifier used inConfident Learning.
Default classifier used is logistic regression.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, <em>default</em>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – This class needs holdout predicted probabilities for every data example
and if not provided, uses cross-validation to compute them.
cv_n_folds sets the number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>prune_method</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>, <em>default</em>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">prune_by_noise_rate</span></code>) – <p>Available options: ‘prune_by_class’, ‘prune_by_noise_rate’, or ‘both’.
This str determines the method used for pruning.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>1. <code class="xref py py-obj docutils literal notranslate"><span class="pre">prune_method=prune_by_noise_rate</span></code>: works by removing examples
with <em>high probability</em> of being mislabeled for every non-diagonal in the
<code class="docutils literal notranslate"><span class="pre">prune_counts_matrix</span></code> (see <code class="docutils literal notranslate"><span class="pre">pruning.py</span></code>).</p>
<p>2. <code class="xref py py-obj docutils literal notranslate"><span class="pre">prune_method=prune_by_class</span></code>: works by removing the examples
with <em>smallest probability</em> of belonging to their given class label for
every class.</p>
<p>3. <code class="xref py py-obj docutils literal notranslate"><span class="pre">prune_method=both</span></code>: Finds the examples satisfying (1) AND (2)
and removes their set conjunction.</p>
</div>
</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code> (Default: <code class="xref py py-class docutils literal notranslate"><span class="pre">False)</span></code>) – If true, forces numerical consistency of latent estimates. Each is
estimated independently, but they are related mathematically with closed
form equivalences. This will iteratively enforce consistency.</p></li>
<li><p><strong>pulearning</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code> (0 or <code class="docutils literal notranslate"><span class="pre">1</span></code>, <em>default</em>: <code class="xref py py-class docutils literal notranslate"><span class="pre">None)</span></code>) – Only works for 2 class datasets. Set to the integer of the class that is
perfectly labeled (certain no errors in that class).</p></li>
<li><p><strong>n_jobs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code> (Windows users may see a speed-up with n_jobs = 1)) – Number of processing threads used by multiprocessing. Default None
sets to the number of processing threads on your CPU.
Set this to 1 to REMOVE parallel processing (if its causing issues).</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.fit" title="cleanlab.classification.LearningWithNoisyLabels.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, s[, psx, thresholds, noise_matrix, ...])</p></td>
<td><p>This method implements the confident learning.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.get_params" title="cleanlab.classification.LearningWithNoisyLabels.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.predict" title="cleanlab.classification.LearningWithNoisyLabels.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(*args, **kwargs)</p></td>
<td><p>Returns a binary vector of predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.predict_proba" title="cleanlab.classification.LearningWithNoisyLabels.predict_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_proba</span></code></a>(*args, **kwargs)</p></td>
<td><p>Returns a vector of probabilties P(y=k) for each example in X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.score" title="cleanlab.classification.LearningWithNoisyLabels.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X, y[, sample_weight])</p></td>
<td><p>Returns the clf's score on a test set X with labels y.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.classification.LearningWithNoisyLabels.set_params" title="cleanlab.classification.LearningWithNoisyLabels.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/classification.html#LearningWithNoisyLabels.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.fit" title="Permalink to this definition">#</a></dt>
<dd><p>This method implements the confident learning. It counts examples
that are likely labeled correctly and incorrectly and uses their ratio
to create a predicted confusion matrix.
This function fits the classifier (self.clf) to (X, s) accounting for
the noise in both the positive and negative sets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>s</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code>) – A binary vector of labels, s, which may contain mislabeling.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> (shape (N, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(s=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x.
This is the probability distribution over all K classes, for each
example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.
If you are not sure, leave psx = None (default) and
it will be computed for you using cross-validation.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">iterable</span></code> (list or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). List of probabilities used to determine the cutoff
predicted probability necessary to consider an example as a given
class label.
Default is <code class="docutils literal notranslate"><span class="pre">None</span></code>. These are computed for you automatically.
If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. Values in list should be between 0 and 1.</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probablity matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probablity matrix of the form P(y=k_y|s=k_s). Contains
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(noise_mask, sample_weight)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.get_params" title="Permalink to this definition">#</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>, <em>default</em> <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>) – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>params</strong> – Parameter names mapped to their values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/classification.html#LearningWithNoisyLabels.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a binary vector of predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(n</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">m)</span></code>) – The test data as a feature matrix.</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/classification.html#LearningWithNoisyLabels.predict_proba"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.predict_proba" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a vector of probabilties P(y=k)
for each example in X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(n</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">m)</span></code>) – The test data as a feature matrix.</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/classification.html#LearningWithNoisyLabels.score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.score" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the clf’s score on a test set X with labels y.
Uses the models default scoring function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(n</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">m)</span></code>) – The test data as a feature matrix.</p></li>
<li><p><strong>y</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(n,)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(n</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1)</span></code>) – The test classification labels as an array.</p></li>
<li><p><strong>sample_weight</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(n,)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(n</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1)</span></code>) – Weights each example when computing the score / accuracy.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.classification.LearningWithNoisyLabels.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#cleanlab.classification.LearningWithNoisyLabels.set_params" title="Permalink to this definition">#</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**params</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>) – Estimator parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Estimator instance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">estimator</span> <span class="pre">instance</span></code></p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.latent_estimation">
<span id="latent-estimation"></span><h1>Latent Estimation<a class="headerlink" href="#module-cleanlab.latent_estimation" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.calibrate_confident_joint" title="cleanlab.latent_estimation.calibrate_confident_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calibrate_confident_joint</span></code></a>(confident_joint, s)</p></td>
<td><p>Calibrates any confident joint estimate P(s=i, y=j) such that np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.compute_confident_joint" title="cleanlab.latent_estimation.compute_confident_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_confident_joint</span></code></a>(s, psx[, K, ...])</p></td>
<td><p>Estimates P(s,y), the confident counts of the latent joint distribution of true and noisy labels using observed s and predicted probabilities psx.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.converge_estimates" title="cleanlab.latent_estimation.converge_estimates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">converge_estimates</span></code></a>(ps, py, noise_matrix, ...)</p></td>
<td><p>Computes py := P(y=k) and both noise_matrix and inverse_noise_matrix, by numerically converging ps := P(s=k), py, and the noise matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba" title="cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_confident_joint_and_cv_pred_proba</span></code></a>(X, s)</p></td>
<td><p>Estimates P(s,y), the confident counts of the latent joint distribution of true and noisy labels using observed s and predicted probabilities psx.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_confident_joint_from_probabilities" title="cleanlab.latent_estimation.estimate_confident_joint_from_probabilities"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_confident_joint_from_probabilities</span></code></a>(s, psx)</p></td>
<td><p>DEPRECATED AS OF VERSION 0.0.8.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_cv_predicted_probabilities" title="cleanlab.latent_estimation.estimate_cv_predicted_probabilities"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_cv_predicted_probabilities</span></code></a>(X, labels)</p></td>
<td><p>This function computes the out-of-sample predicted probability [P(s=k|x)] for every example in X using cross validation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_joint" title="cleanlab.latent_estimation.estimate_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_joint</span></code></a>(s[, psx, confident_joint, ...])</p></td>
<td><p>Estimates the joint distribution of label noise P(s=i, y=j) guaranteed to</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_latent" title="cleanlab.latent_estimation.estimate_latent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_latent</span></code></a>(confident_joint, s[, ...])</p></td>
<td><p>Computes the latent prior p(y), the noise matrix P(s|y) and the inverse noise matrix P(y|s) from the <cite>confident_joint</cite> count(s, y).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_noise_matrices" title="cleanlab.latent_estimation.estimate_noise_matrices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_noise_matrices</span></code></a>(X, s[, clf, ...])</p></td>
<td><p>Estimates the noise_matrix of shape (K, K).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_py_and_noise_matrices_from_probabilities" title="cleanlab.latent_estimation.estimate_py_and_noise_matrices_from_probabilities"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_py_and_noise_matrices_from_probabilities</span></code></a>(s, psx)</p></td>
<td><p>Computes the confident counts estimate of latent variables py and the noise rates using observed s and predicted probabilities psx.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.estimate_py_noise_matrices_and_cv_pred_proba" title="cleanlab.latent_estimation.estimate_py_noise_matrices_and_cv_pred_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_py_noise_matrices_and_cv_pred_proba</span></code></a>(X, s)</p></td>
<td><p>This function computes the out-of-sample predicted probability P(s=k|x) for every example x in X using cross validation while also computing the confident counts noise rates within each cross-validated subset and returning the average noise rate across all examples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_estimation.num_label_errors" title="cleanlab.latent_estimation.num_label_errors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">num_label_errors</span></code></a>(labels, psx[, confident_joint])</p></td>
<td><p>Estimates the number of label errors in <cite>labels</cite>.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.calibrate_confident_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">calibrate_confident_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#calibrate_confident_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.calibrate_confident_joint" title="Permalink to this definition">#</a></dt>
<dd><p>Calibrates any confident joint estimate P(s=i, y=j) such that
np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p>
<p>In other words, this function forces the confident joint to have the
true noisy prior p(s) (summed over columns for each row) and also
forces the confident joint to add up to the total number of examples.</p>
<p>This method makes the confident joint a valid counts estimate
of the actual joint of noisy and true labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – A K,K integer matrix of count(s=k, y=k). Estimates a confident subset of
the joint disribution of the noisy and true labels P_{s,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (s=j, y=k) classes.</p></li>
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>multi_label</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, s should be an iterable (e.g. list) of iterables, containing a
list of labels for each example, instead of just a single label.
The MAJOR DIFFERENCE in how this is calibrated versus single_label,
is the total number of errors considered is based on the number
of labels, not the number of examples. So, the calibrated
confident_joint will sum to the number of total labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">float</span> <span class="pre">representing</span> <span class="pre">a</span> <span class="pre">valid</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">estimate</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">joint</span> <span class="pre">COUNTS</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">noisy</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">true</span> <span class="pre">labels.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.compute_confident_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">compute_confident_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_indices_of_off_diagonals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#compute_confident_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.compute_confident_joint" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates P(s,y), the confident counts of the latent
joint distribution of true and noisy labels
using observed s and predicted probabilities psx.</p>
<p>This estimate is called the confident joint.</p>
<p>When calibrate = True, this method returns an estimate of
the latent true joint counts of noisy and true labels.</p>
<p>Important! This function assumes that psx are out-of-sample
holdout probabilities. This can be done with cross validation. If
the probabilities are not computed out-of-sample, overfitting may occur.</p>
<p>This function estimates the joint of shape (K, K). This is the
confident counts of examples in every class, labeled as every other class.</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, the estimate is within 1 percent of the truth.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>K</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">None)</span></code>) – Number of unique classes. Calculated as len(np.unique(s)) when K == None</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(s=i, y=j) such that
np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p></li>
<li><p><strong>multi_label</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, s should be an iterable (e.g. list) of iterables, containing a
list of labels for each example, instead of just a single label.</p></li>
<li><p><strong>return_indices_of_off_diagonals</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true returns indices of examples that were counted in off-diagonals
of confident joint as a baseline proxy for the label errors. This
somtimes works as well as pruning.get_noise_indices(confident_joint).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>We provide a for-loop based simplification of the confident joint
below. This implementation is not efficient, not used in practice, and
not complete, but covers the jist of how the confident joint is computed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Confident examples are those that we are confident have label y = k</span>
<span class="c1"># Estimate (K, K) matrix of confident examples with s = k_s and y = k_y</span>
<span class="n">cj_ish</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span> <span class="c1"># k_s is the class value k of noisy label s</span>
    <span class="k">for</span> <span class="n">k_y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span> <span class="c1"># k_y is the (guessed) class k of true label y</span>
        <span class="n">cj_ish</span><span class="p">[</span><span class="n">k_s</span><span class="p">][</span><span class="n">k_y</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">psx</span><span class="p">[:,</span><span class="n">k_y</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">thresholds</span><span class="p">[</span><span class="n">k_y</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1e-8</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="n">k_s</span><span class="p">))</span>
</pre></div>
</div>
<p>The following is a vectorized (but non-parallelized) implementation of the
confident joint, again slow, using for-loops/simplified for understanding.
This implementation is 100% accurate, its just not optimized for speed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">confident_joint</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">psx</span><span class="p">):</span>
    <span class="n">s_label</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">confident_bins</span> <span class="o">=</span> <span class="n">row</span> <span class="o">&gt;=</span> <span class="n">thresholds</span> <span class="o">-</span> <span class="mf">1e-6</span>
    <span class="n">num_confident_bins</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">confident_bins</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_confident_bins</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">confident_joint</span><span class="p">[</span><span class="n">s_label</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">confident_bins</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">num_confident_bins</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">confident_joint</span><span class="p">[</span><span class="n">s_label</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">row</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.converge_estimates">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">converge_estimates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inv_noise_matrix_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#converge_estimates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.converge_estimates" title="Permalink to this definition">#</a></dt>
<dd><p>Computes py := P(y=k) and both noise_matrix and inverse_noise_matrix,
by numerically converging ps := P(s=k), py, and the noise matrices.</p>
<p>Forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p>
<p>py := P(y=k) and the inverse noise matrix P(y=k_y|s=k_s) specify one
another, meaning one can be computed from the other and vice versa.
When numerical discrepancy exists due to poor estimation, they can be made
to agree by repeatedly computing one from the other,
for some a certain number of iterations (3-10 works fine.)</p>
<p>Do not set iterations too high or performance will decrease as small
deviations will get perturbed over and over and potentially magnified.</p>
<p>Note that we have to first converge the inverse_noise_matrix and py,
then we can update the noise_matrix, then repeat. This is because the
inverse noise matrix depends on py (which is unknown/latent), but the
noise matrix depends on ps (which is known), so there will be no change in
the noise matrix if we recompute it when py and inverse_noise_matrix change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The fraction (prior probability) of each observed, NOISY class P(s = k).</p></li>
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The estimated fraction (prior probability) of each TRUE class P(y = k).</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(y=k_y|s=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
<li><p><strong>inv_noise_matrix_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(Default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">5)</span></code>) – Number of times to converge inverse noise matrix with py and noise mat.</p></li>
<li><p><strong>noise_matrix_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(Default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">3)</span></code>) – Number of times to converge noise matrix with py and inverse noise mat.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Three</span> <span class="pre">np.arrays</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">form</span> <span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix)</span> <span class="pre">all</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">having</span> <span class="pre">numerical</span> <span class="pre">agreement</span> <span class="pre">in</span> <span class="pre">terms</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">their</span> <span class="pre">mathematical</span> <span class="pre">relations.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_confident_joint_and_cv_pred_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_confident_joint_and_cv_pred_proba"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_confident_joint_and_cv_pred_proba" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates P(s,y), the confident counts of the latent
joint distribution of true and noisy labels
using observed s and predicted probabilities psx.</p>
<p>The output of this function is a numpy array of shape (K, K).</p>
<p>Under certain conditions, estimates are exact, and in many
conditions, estimates are within one percent of actual.</p>
<p>Notes: There are two ways to compute the confident joint with pros/cons.
1. For each holdout set, we compute the confident joint, then sum them up.
2. Compute pred_proba for each fold, combine, compute the confident joint.
(1) is more accurate because it correctly computes thresholds for each fold
(2) is more accurate when you have only a little data because it computes
the confident joint using all the probabilities. For example if you had 100
examples, with 5-fold cross validation + uniform p(y) you would only have 20
examples to compute each confident joint for (1). Such small amounts of data
is bound to result in estimation errors. For this reason, we implement (2),
but we implement (1) as a commented out function at the end of this file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(s=i, y=j) such that
np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Returns</span> <span class="pre">a</span> <span class="pre">tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">two</span> <span class="pre">numpy</span> <span class="pre">array</span> <span class="pre">matrices</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">form</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">(joint</span> <span class="pre">counts</span> <span class="pre">matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">predicted</span> <span class="pre">probability</span> <span class="pre">matrix)</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_confident_joint_from_probabilities">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_confident_joint_from_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_list_of_converging_cj_matrices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_confident_joint_from_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_confident_joint_from_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>DEPRECATED AS OF VERSION 0.0.8.
REMOVED AS OF VERSION 0.0.10.</p>
<p>Estimates P(s,y), the confident counts of the latent
joint distribution of true and noisy labels
using observed s and predicted probabilities psx.</p>
<p>UNLIKE compute_confident_joint, this function calibrates
the confident joint estimate P(s=i, y=j) such that
np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes  the noisy label instead of     ilde(y), for ASCII reasons.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>force_ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If true, forces the output confident_joint matrix to have p(s) closer to
the true p(s). The method used is SGD with a learning rate of eta = 0.5.
If force_ps is an integer, it represents the number of epochs. Setting
this to True is not always good. To make p(s) match, fewer confident
examples are used to estimate the confident_joint, resulting in poorer
estimation of the overall matrix even if p(s) is more accurate.</p></li>
<li><p><strong>return_list_of_converging_cj_matrices</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">False)</span></code>) – When force_ps is true, it converges the joint count matrix that is
returned. Setting this to true will return the list of the converged
matrices. The first item in the list is the original and
the last item is the final result.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>confident_joint matrix count(s, y)</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>)</p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">where</span> <span class="pre">np.sum(confident_joint)</span> <span class="pre">~</span> <span class="pre">len(s)</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">rows</span> <span class="pre">sum</span></code> to <code class="xref py py-class docutils literal notranslate"><span class="pre">np.bincount(s)</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_cv_predicted_probabilities">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_cv_predicted_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_cv_predicted_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_cv_predicted_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>This function computes the out-of-sample predicted
probability [P(s=k|x)] for every example in X using cross
validation. Output is a np.array of shape (N, K) where N is
the number of training examples and K is the number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">ints</span> <span class="pre">from</span> <span class="pre">[0,1,..,K-1]</span></code>) – A discrete vector of class labels which may or may not contain mislabeling</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>psx</strong> – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_joint" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Estimates the joint distribution of label noise P(s=i, y=j) guaranteed to</dt><dd><ul class="simple">
<li><p>sum to 1</p></li>
<li><p>np.sum(joint_estimate, axis = 1) == p(s)</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>docstring.</strong> (<em>See cleanlab.latent_estimation.calibrate_confident_joint</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">float</span> <span class="pre">representing</span> <span class="pre">a</span> <span class="pre">valid</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">estimate</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">true</span> <span class="pre">joint</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">noisy</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">true</span> <span class="pre">labels.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_latent">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_latent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_latent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_latent" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the latent prior p(y), the noise matrix P(s|y) and the
inverse noise matrix P(y|s) from the <cite>confident_joint</cite> count(s, y). The
<cite>confident_joint</cite> estimated by <cite>compute_confident_joint</cite>
by counting confident examples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">int)</span></code>) – A K,K integer matrix of count(s=k, y=k). Estimates a a confident subset
of the joint disribution of the noisy and true labels P_{s,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (s=j, y=k) classes.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(y=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">tuple</span> <span class="pre">containing</span> <span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inv_noise_matrix).</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_noise_matrices">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_noise_matrices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_noise_matrices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_noise_matrices" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(s=k_s|y=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">two-item</span> <span class="pre">tuple</span> <span class="pre">containing</span> <span class="pre">(noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inv_noise_matrix).</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_py_and_noise_matrices_from_probabilities">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_py_and_noise_matrices_from_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_py_and_noise_matrices_from_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_py_and_noise_matrices_from_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the confident counts
estimate of latent variables py and the noise rates
using observed s and predicted probabilities psx.</p>
<p>Important! This function assumes that psx are out-of-sample
holdout probabilities. This can be done with cross validation. If
the probabilities are not computed out-of-sample, overfitting may occur.</p>
<p>This function estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(s=k_s|y=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(y=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(s=i, y=j) such that
np.sum(cj) == len(s) and np.sum(cj, axis = 1) == np.bincount(s).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.estimate_py_noise_matrices_and_cv_pred_proba">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">estimate_py_noise_matrices_and_cv_pred_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#estimate_py_noise_matrices_and_cv_pred_proba"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.estimate_py_noise_matrices_and_cv_pred_proba" title="Permalink to this definition">#</a></dt>
<dd><p>This function computes the out-of-sample predicted
probability P(s=k|x) for every example x in X using cross
validation while also computing the confident counts noise
rates within each cross-validated subset and returning
the average noise rate across all examples.</p>
<p>This function estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(s=k_s|y=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of      ilde(y), for ASCII reasons.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(s^=k|s=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having hidden label y = k. This is
not used for pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(y=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Returns</span> <span class="pre">a</span> <span class="pre">tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">five</span> <span class="pre">numpy</span> <span class="pre">array</span> <span class="pre">matrices</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">form</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix,</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">joint</span> <span class="pre">count</span> <span class="pre">matrix</span> <span class="pre">i.e.</span> <span class="pre">confident</span> <span class="pre">joint</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">predicted</span> <span class="pre">probability</span> <span class="pre">matrix)</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_estimation.num_label_errors">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_estimation.</span></span><span class="sig-name descname"><span class="pre">num_label_errors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_estimation.html#num_label_errors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_estimation.num_label_errors" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates the number of label errors in <cite>labels</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">int)</span></code>) – A K,K integer matrix of count(s=k, y=k). Estimates a confident subset of
the joint disribution of the noisy and true labels P_{s,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (s=j, y=k) classes.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">integer</span> <span class="pre">estimating</span> <span class="pre">the</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">label</span> <span class="pre">errors.</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.noise_generation">
<span id="noise-generation"></span><h1>Noise Generation<a class="headerlink" href="#module-cleanlab.noise_generation" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.noise_generation.generate_n_rand_probabilities_that_sum_to_m" title="cleanlab.noise_generation.generate_n_rand_probabilities_that_sum_to_m"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_n_rand_probabilities_that_sum_to_m</span></code></a>(n, m)</p></td>
<td><p>When min_prob=0 and max_prob = 1.0, this method is deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.noise_generation.generate_noise_matrix" title="cleanlab.noise_generation.generate_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_noise_matrix</span></code></a>(K[, max_noise_rate, ...])</p></td>
<td><p>DEPRECATED - Use generate_noise_matrix_from_trace()</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.noise_generation.generate_noise_matrix_from_trace" title="cleanlab.noise_generation.generate_noise_matrix_from_trace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_noise_matrix_from_trace</span></code></a>(K, trace[, ...])</p></td>
<td><p>Generates a K x K noise matrix P(s=k_s|y=k_y) with trace as the np.mean(np.diagonal(noise_matrix)).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.noise_generation.generate_noisy_labels" title="cleanlab.noise_generation.generate_noisy_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_noisy_labels</span></code></a>(y, noise_matrix[, verbose])</p></td>
<td><p>Generates noisy labels s (shape (N, 1)) from perfect labels y, 'exactly' yielding the provided noise_matrix between s and y.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.noise_generation.noise_matrix_is_valid" title="cleanlab.noise_generation.noise_matrix_is_valid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">noise_matrix_is_valid</span></code></a>(noise_matrix, py[, ...])</p></td>
<td><p>Given a prior py = p(y=k), returns true if the given noise_matrix is a learnable matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.noise_generation.randomly_distribute_N_balls_into_K_bins" title="cleanlab.noise_generation.randomly_distribute_N_balls_into_K_bins"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randomly_distribute_N_balls_into_K_bins</span></code></a>(N, K)</p></td>
<td><p>Returns a uniformly random numpy integer array of length N that sums to K.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.generate_n_rand_probabilities_that_sum_to_m">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">generate_n_rand_probabilities_that_sum_to_m</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#generate_n_rand_probabilities_that_sum_to_m"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.generate_n_rand_probabilities_that_sum_to_m" title="Permalink to this definition">#</a></dt>
<dd><p>When min_prob=0 and max_prob = 1.0, this method is deprecated.
Instead use np.random.dirichlet(np.ones(n))*m</p>
<p>Generates ‘n’ random probabilities that sum to ‘m’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Length of np.array of random probabilities to be returned.</p></li>
<li><p><strong>m</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Sum of np.array of random probabilities that is returned.</p></li>
<li><p><strong>max_prob</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">(0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0]</span> <span class="pre">|</span> <span class="pre">Default</span> <span class="pre">value</span> <span class="pre">is</span> <span class="pre">1.0</span></code>) – Maximum probability of any entry in the returned np.array.</p></li>
<li><p><strong>min_prob</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">[0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0)</span> <span class="pre">|</span> <span class="pre">Default</span> <span class="pre">value</span> <span class="pre">is</span> <span class="pre">0.0</span></code>) – Minimum probability of any entry in the returned np.array.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.generate_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">generate_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_noise_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_zero_noise_rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#generate_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.generate_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>DEPRECATED - Use generate_noise_matrix_from_trace()</p>
<p>Generates a noise matrix by randomly assigning noise rates
up to max_noise_rate, then setting noise rates to
zero until P(s!=k|s=k) &lt; 1 is satisfied. Additionally,
frac_zero_noise_rates are set to zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Creates a noise matrix of shape (K, K). Implies there are
K classes for learning with noisy labels.</p></li>
<li><p><strong>max_noise_rate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Smaller —&gt; easier learning problem (less noise)</p></li>
<li><p><strong>frac_zero_noise_rates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Make problem more tractable by making a fraction of noise rates zero.
Larger –&gt; Easier learning problem</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Print debugging output if set to True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.generate_noise_matrix_from_trace">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">generate_noise_matrix_from_trace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_trace_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_trace_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_noise_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_noise_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_noise_matrix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_zero_noise_rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#generate_noise_matrix_from_trace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.generate_noise_matrix_from_trace" title="Permalink to this definition">#</a></dt>
<dd><p>Generates a K x K noise matrix P(s=k_s|y=k_y) with trace
as the np.mean(np.diagonal(noise_matrix)).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Creates a noise matrix of shape (K, K). Implies there are
K classes for learning with noisy labels.</p></li>
<li><p><strong>trace</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">(0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0]</span></code>) – Sum of diagonal entries of np.array of random probabilities returned.</p></li>
<li><p><strong>max_trace_prob</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">(0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0]</span></code>) – Maximum probability of any entry in the trace of the return matrix.</p></li>
<li><p><strong>min_trace_prob</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">[0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0)</span></code>) – Minimum probability of any entry in the trace of the return matrix.</p></li>
<li><p><strong>max_noise_rate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">(0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0]</span></code>) – Maximum noise_rate (non-diagonal entry) in the returned np.array.</p></li>
<li><p><strong>min_noise_rate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span> <span class="pre">[0.0</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1.0)</span></code>) – Minimum noise_rate (non-diagonal entry) in the returned np.array.</p></li>
<li><p><strong>valid_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, returns a matrix having all necessary conditions for
learning with noisy labels. In particular, p(y=k)p(s=k) &lt; p(y=k,s=k)
is satisfied. This requires that Trace &gt; 1.</p></li>
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – Fraction (prior probability) of each true/hidden class label, P(y = k).
REQUIRED when valid_noise_matrix == True.</p></li>
<li><p><strong>frac_zero_noise_rates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The fraction of the n*(n-1) noise rates
that will be set to 0. Note that if you set a high trace, it may be
impossible to also have a low fraction of zero noise rates without
forcing all non-“1” diagonal values. Instead, when this happens we only
guarantee to produce a noise matrix with frac_zero_noise_rates <strong>or
higher</strong>. The opposite occurs with a small trace.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Seeds the random number generator for numpy.</p></li>
<li><p><strong>max_iter</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">10000)</span></code>) – The max number of tries to produce a valid matrix before returning False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>noise matrix P(s=k_s|y=k_y) with trace
as the np.sum(np.diagonal(noise_matrix)).
This a conditional probability matrix and a
left stochastic matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.generate_noisy_labels">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">generate_noisy_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#generate_noisy_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.generate_noisy_labels" title="Permalink to this definition">#</a></dt>
<dd><p>Generates noisy labels s (shape (N, 1)) from perfect labels y,
‘exactly’ yielding the provided noise_matrix between s and y.</p>
<p>Below we provide a for loop implementation of what this function does.
We do not use this implementation as it is not a fast algorithm, but
it explains as Python pseudocode what is happening in this function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – Perfect labels, without any noise. Contains K distinct natural number
classes, e.g. 0, 1,…, K-1</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probablity matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate s</span>
<span class="n">count_joint</span> <span class="o">=</span> <span class="p">(</span><span class="n">noise_matrix</span> <span class="o">*</span> <span class="n">py</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k_y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k_s</span> <span class="o">!=</span> <span class="n">k_y</span><span class="p">:</span>
            <span class="n">idx_flip</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">s</span><span class="o">==</span><span class="n">k_y</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="n">k_y</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx_flip</span><span class="p">):</span> <span class="c1"># pragma: no cover</span>
                <span class="n">s</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                    <span class="n">idx_flip</span><span class="p">,</span>
                    <span class="n">count_joint</span><span class="p">[</span><span class="n">k_s</span><span class="p">][</span><span class="n">k_y</span><span class="p">],</span>
                    <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)]</span> <span class="o">=</span> <span class="n">k_s</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.noise_matrix_is_valid">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">noise_matrix_is_valid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#noise_matrix_is_valid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.noise_matrix_is_valid" title="Permalink to this definition">#</a></dt>
<dd><p>Given a prior py = p(y=k), returns true if the given noise_matrix is a
learnable matrix. Learnability means that it is possible to achieve
better than random performance, on average, for the amount of noise in
noise_matrix.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.noise_generation.randomly_distribute_N_balls_into_K_bins">
<span class="sig-prename descclassname"><span class="pre">cleanlab.noise_generation.</span></span><span class="sig-name descname"><span class="pre">randomly_distribute_N_balls_into_K_bins</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_balls_per_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_balls_per_bin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/noise_generation.html#randomly_distribute_N_balls_into_K_bins"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.noise_generation.randomly_distribute_N_balls_into_K_bins" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a uniformly random numpy integer array of length N that sums
to K.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – </p></li>
<li><p><strong>K</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – </p></li>
<li><p><strong>max_balls_per_bin</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – </p></li>
<li><p><strong>min_balls_per_bin</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.baseline_methods">
<span id="baseline-methods"></span><h1>Baseline Methods<a class="headerlink" href="#module-cleanlab.baseline_methods" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.baseline_methods.baseline_argmax" title="cleanlab.baseline_methods.baseline_argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">baseline_argmax</span></code></a>(psx, s)</p></td>
<td><p>This is the simplest baseline approach.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.baseline_methods.baseline_argmax_calibrated_confusion_matrix" title="cleanlab.baseline_methods.baseline_argmax_calibrated_confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">baseline_argmax_calibrated_confusion_matrix</span></code></a>(psx, s)</p></td>
<td><p>docstring is the same as baseline_argmax_confusion_matrix Except in this method, we calibrate the confident joint created using the confusion matrix before using cleanlab to find the label errors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.baseline_methods.baseline_argmax_confusion_matrix" title="cleanlab.baseline_methods.baseline_argmax_confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">baseline_argmax_confusion_matrix</span></code></a>(psx, s[, ...])</p></td>
<td><p>This is a baseline approach.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.baseline_methods.baseline_argmax">
<span class="sig-prename descclassname"><span class="pre">cleanlab.baseline_methods.</span></span><span class="sig-name descname"><span class="pre">baseline_argmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/baseline_methods.html#baseline_argmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.baseline_methods.baseline_argmax" title="Permalink to this definition">#</a></dt>
<dd><p>This is the simplest baseline approach. Just consider
anywhere argmax != s as a label error.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the
N examples x. This is the probability distribution over all K classes,
for each example, regarding whether the example has label s==k P(s=k|x).
psx should have been computed using 3 (or higher) fold cross-validation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">boolean</span> <span class="pre">mask</span> <span class="pre">that</span> <span class="pre">is</span> <span class="pre">true</span> <span class="pre">if</span> <span class="pre">the</span> <span class="pre">example</span> <span class="pre">belong</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">to</span> <span class="pre">that</span> <span class="pre">index</span> <span class="pre">is</span> <span class="pre">label</span> <span class="pre">error..</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.baseline_methods.baseline_argmax_calibrated_confusion_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.baseline_methods.</span></span><span class="sig-name descname"><span class="pre">baseline_argmax_calibrated_confusion_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prune_by_noise_rate'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/baseline_methods.html#baseline_argmax_calibrated_confusion_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.baseline_methods.baseline_argmax_calibrated_confusion_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>docstring is the same as baseline_argmax_confusion_matrix
Except in this method, we calibrate the confident joint created using
the confusion matrix before using cleanlab to find the label errors.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.baseline_methods.baseline_argmax_confusion_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.baseline_methods.</span></span><span class="sig-name descname"><span class="pre">baseline_argmax_confusion_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prune_by_noise_rate'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/baseline_methods.html#baseline_argmax_confusion_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.baseline_methods.baseline_argmax_confusion_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>This is a baseline approach. That uses the a confusion matrix
of argmax(psx) and s as the confident joint and then uses cleanlab
(confident learning) to find the label errors using this matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the
N examples x. This is the probability distribution over all K classes,
for each example, regarding whether the example has label s==k P(s=k|x).
psx should have been computed using 3 (or higher) fold cross-validation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">boolean</span> <span class="pre">mask</span> <span class="pre">that</span> <span class="pre">is</span> <span class="pre">true</span> <span class="pre">if</span> <span class="pre">the</span> <span class="pre">example</span> <span class="pre">belong</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">to</span> <span class="pre">that</span> <span class="pre">index</span> <span class="pre">is</span> <span class="pre">label</span> <span class="pre">error..</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.coteaching">
<span id="co-teaching"></span><h1>Co-Teaching<a class="headerlink" href="#module-cleanlab.coteaching" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.coteaching.adjust_learning_rate" title="cleanlab.coteaching.adjust_learning_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_learning_rate</span></code></a>(optimizer, epoch, ...)</p></td>
<td><p>Scheduler to adjust learning rate and betas for Adam Optimizer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.coteaching.evaluate" title="cleanlab.coteaching.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(test_loader, model1, model2)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.coteaching.forget_rate_scheduler" title="cleanlab.coteaching.forget_rate_scheduler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forget_rate_scheduler</span></code></a>(epochs, forget_rate, ...)</p></td>
<td><p>Tells Co-Teaching what fraction of examples to forget at each epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.coteaching.initialize_lr_scheduler" title="cleanlab.coteaching.initialize_lr_scheduler"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_lr_scheduler</span></code></a>([lr, epochs, ...])</p></td>
<td><p>Scheduler to adjust learning rate and betas for Adam Optimizer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.coteaching.loss_coteaching" title="cleanlab.coteaching.loss_coteaching"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loss_coteaching</span></code></a>(y_1, y_2, t, forget_rate[, ...])</p></td>
<td><p>Co-Teaching Loss function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.coteaching.train" title="cleanlab.coteaching.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>(train_loader, epoch, model1, ...)</p></td>
<td><p>PyTorch training function.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.adjust_learning_rate">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">adjust_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_plan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1_plan</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#adjust_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.adjust_learning_rate" title="Permalink to this definition">#</a></dt>
<dd><p>Scheduler to adjust learning rate and betas for Adam Optimizer</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.evaluate">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.evaluate" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.forget_rate_scheduler">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">forget_rate_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forget_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gradual</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exponent</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#forget_rate_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.forget_rate_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Tells Co-Teaching what fraction of examples to forget at each epoch.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.initialize_lr_scheduler">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">initialize_lr_scheduler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">250</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_decay_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">80</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#initialize_lr_scheduler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.initialize_lr_scheduler" title="Permalink to this definition">#</a></dt>
<dd><p>Scheduler to adjust learning rate and betas for Adam Optimizer</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.loss_coteaching">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">loss_coteaching</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forget_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#loss_coteaching"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.loss_coteaching" title="Permalink to this definition">#</a></dt>
<dd><p>Co-Teaching Loss function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_1</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">array</span></code>) – Output logits from model 1</p></li>
<li><p><strong>y_2</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">array</span></code>) – Output logits from model 2</p></li>
<li><p><strong>t</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – List of Noisy Labels (t means targets)</p></li>
<li><p><strong>forget_rate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Decimal between 0 and 1 for how quickly the models forget what they learn.
Just use rate_schedule[epoch] for this value</p></li>
<li><p><strong>class_weights</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">array</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(Number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span> <span class="pre">x</span> <span class="pre">1)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Default</span></code>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>) – A np.torch.tensor list of length number of classes with weights</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.coteaching.train">
<span class="sig-prename descclassname"><span class="pre">cleanlab.coteaching.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forget_rate_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accuracy</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/coteaching.html#train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.coteaching.train" title="Permalink to this definition">#</a></dt>
<dd><p>PyTorch training function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_loader</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code>) – </p></li>
<li><p><strong>epoch</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – </p></li>
<li><p><strong>model1</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">PyTorch</span> <span class="pre">class</span> <span class="pre">inheriting</span> <span class="pre">nn.Module</span></code>) – Must define __init__ and forward(self, x,)</p></li>
<li><p><strong>optimizer1</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">PyTorch</span> <span class="pre">torch.optim.Adam</span></code>) – </p></li>
<li><p><strong>model2</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">PyTorch</span> <span class="pre">class</span> <span class="pre">inheriting</span> <span class="pre">nn.Module</span></code>) – Must define __init__ and forward(self, x,)</p></li>
<li><p><strong>optimizer2</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">PyTorch</span> <span class="pre">torch.optim.Adam</span></code>) – </p></li>
<li><p><strong>args</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">parser.parse_args()</span> <span class="pre">object</span></code>) – Must contain num_iter_per_epoch, print_freq, and epochs</p></li>
<li><p><strong>forget_rate_schedule</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">length</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">epochs</span></code>) – Tells Co-Teaching loss what fraction of examples to forget about.</p></li>
<li><p><strong>class_weights</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span> <span class="pre">array</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(Number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span> <span class="pre">x</span> <span class="pre">1)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Default</span></code>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>) – A np.torch.tensor list of length number of classes with weights</p></li>
<li><p><strong>accuracy</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">function</span></code>) – A function of the form accuracy(output, target, topk=(1,)) for
computing top1 and top5 accuracy given output and true targets.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.latent_algebra">
<span id="latent-algebra"></span><h1>Latent Algebra<a class="headerlink" href="#module-cleanlab.latent_algebra" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_inv_noise_matrix" title="cleanlab.latent_algebra.compute_inv_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_inv_noise_matrix</span></code></a>(py, noise_matrix[, ps])</p></td>
<td><p>Compute the inverse noise matrix if py := P(y=k) is given.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_noise_matrix_from_inverse" title="cleanlab.latent_algebra.compute_noise_matrix_from_inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_noise_matrix_from_inverse</span></code></a>(ps, ...[, py])</p></td>
<td><p>Compute the noise matrix P(s=k_s|y=k_y).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_ps_py_inv_noise_matrix" title="cleanlab.latent_algebra.compute_ps_py_inv_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_ps_py_inv_noise_matrix</span></code></a>(s, noise_matrix)</p></td>
<td><p>Compute ps := P(s=k), py := P(y=k), and the inverse noise matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_py" title="cleanlab.latent_algebra.compute_py"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_py</span></code></a>(ps, noise_matrix, ...[, ...])</p></td>
<td><p>Compute py := P(y=k) from ps := P(s=k), noise_matrix, and the inverse noise matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_py_inv_noise_matrix" title="cleanlab.latent_algebra.compute_py_inv_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_py_inv_noise_matrix</span></code></a>(ps, noise_matrix)</p></td>
<td><p>Compute py := P(y=k), and the inverse noise matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.latent_algebra.compute_pyx" title="cleanlab.latent_algebra.compute_pyx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_pyx</span></code></a>(psx, noise_matrix, ...)</p></td>
<td><p>Compute pyx := P(y=k|x) from psx := P(s=k|x), and the noise_matrix and inverse noise matrix.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_inv_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_inv_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">py</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_inv_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_inv_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the inverse noise matrix if py := P(y=k) is given.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each TRUE class label, P(y = k)</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each NOISY given label, P(s = k).
ps is easily computable from py and should only be provided if it has
already been precomputed, to increase code efficiency.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>For loop based implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of classes</span>
<span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">py</span><span class="p">)</span>

<span class="c1"># 'ps' is p(s=k) = noise_matrix * p(y=k)</span>
<span class="c1"># because in *vector computation*: P(s=k|y=k) * p(y=k) = P(s=k)</span>
<span class="k">if</span> <span class="n">ps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">noise_matrix</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">py</span><span class="p">)</span>

<span class="c1"># Estimate the (K, K) inverse noise matrix P(y = k_y | s = k_s)</span>
<span class="n">inverse_noise_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
<span class="c1"># k_s is the class value k of noisy label s</span>
<span class="k">for</span> <span class="n">k_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="c1"># k_y is the (guessed) class value k of true label y</span>
    <span class="k">for</span> <span class="n">k_y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="c1"># P(y|s) = P(s|y) * P(y) / P(s)</span>
        <span class="n">inverse_noise_matrix</span><span class="p">[</span><span class="n">k_y</span><span class="p">][</span><span class="n">k_s</span><span class="p">]</span> <span class="o">=</span> <span class="n">noise_matrix</span><span class="p">[</span><span class="n">k_s</span><span class="p">][</span><span class="n">k_y</span><span class="p">]</span> <span class="o">*</span>                                                  <span class="n">py</span><span class="p">[</span><span class="n">k_y</span><span class="p">]</span> <span class="o">/</span> <span class="n">ps</span><span class="p">[</span><span class="n">k_s</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_noise_matrix_from_inverse">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_noise_matrix_from_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_noise_matrix_from_inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_noise_matrix_from_inverse" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the noise matrix P(s=k_s|y=k_y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each TRUE class label, P(y = k)</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(y=k_y|s=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each observed NOISY label, P(s = k).
ps is easily computable from py and should only be provided if it has
already been precomputed, to increase code efficiency.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>noise_matrix</strong> – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Columns of noise_matrix sum to 1.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>For loop based implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of classes s</span>
<span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>

<span class="c1"># 'py' is p(y=k) = inverse_noise_matrix * p(y=k)</span>
<span class="c1"># because in *vector computation*: P(y=k|s=k) * p(s=k) = P(y=k)</span>
<span class="k">if</span> <span class="n">py</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">py</span> <span class="o">=</span> <span class="n">inverse_noise_matrix</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>

<span class="c1"># Estimate the (K, K) noise matrix P(s = k_s | y = k_y)</span>
<span class="n">noise_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">K</span><span class="p">))</span>
<span class="c1"># k_s is the class value k of noisy label s</span>
<span class="k">for</span> <span class="n">k_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
    <span class="c1"># k_y is the (guessed) class value k of true label y</span>
    <span class="k">for</span> <span class="n">k_y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="c1"># P(s|y) = P(y|s) * P(s) / P(y)</span>
        <span class="n">noise_matrix</span><span class="p">[</span><span class="n">k_s</span><span class="p">][</span><span class="n">k_y</span><span class="p">]</span> <span class="o">=</span> <span class="n">inverse_noise_matrix</span><span class="p">[</span><span class="n">k_y</span><span class="p">][</span><span class="n">k_s</span><span class="p">]</span> <span class="o">*</span>                                          <span class="n">ps</span><span class="p">[</span><span class="n">k_s</span><span class="p">]</span> <span class="o">/</span> <span class="n">py</span><span class="p">[</span><span class="n">k_y</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_ps_py_inv_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_ps_py_inv_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_ps_py_inv_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_ps_py_inv_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Compute ps := P(s=k), py := P(y=k), and the inverse noise matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of labels, s, which may contain mislabeling. “s”
denotes the noisy label instead of tilde(y), for ASCII reasons.</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_py">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_py</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_py"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_py" title="Permalink to this definition">#</a></dt>
<dd><p>Compute py := P(y=k) from ps := P(s=k), noise_matrix, and the
inverse noise matrix.</p>
<p>This method is ** ROBUST ** when py_method = ‘cnt’
It may work well even when the noise matrices are estimated
poorly by using the diagonals of the matrices
instead of all the probabilities in the entire matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The fraction (prior probability) of each observed, noisy label, P(s = k)</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(y=k_y|s=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(y=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>y_count</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The marginal counts of the confident joint (like cj.sum(axis = 0))</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>py</strong> – The fraction (prior probability) of each TRUE class label, P(y = k).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_py_inv_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_py_inv_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_py_inv_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_py_inv_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Compute py := P(y=k), and the inverse noise matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The fraction (prior probability) of each observed, NOISY class P(s = k).</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.latent_algebra.compute_pyx">
<span class="sig-prename descclassname"><span class="pre">cleanlab.latent_algebra.</span></span><span class="sig-name descname"><span class="pre">compute_pyx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/latent_algebra.html#compute_pyx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.latent_algebra.compute_pyx" title="Permalink to this definition">#</a></dt>
<dd><p>Compute pyx := P(y=k|x) from psx := P(s=k|x), and the noise_matrix and
inverse noise matrix.</p>
<p>This method is ROBUST - meaning it works well even when the
noise matrices are estimated poorly by only using the diagonals of the
matrices which tend to be easy to estimate correctly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x. This is the probability distribution over all K classes, for
each example, regarding whether the example has label s==k P(s=k|x). psx
should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(y=k_y|s=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>pyx</strong> – P(y=k|x) is a matrix with K probabilities for all N examples x.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.pruning">
<span id="pruning"></span><h1>Pruning<a class="headerlink" href="#module-cleanlab.pruning" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.pruning.get_noise_indices" title="cleanlab.pruning.get_noise_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_noise_indices</span></code></a>(s, psx[, ...])</p></td>
<td><p>Returns the indices of most likely (confident) label errors in s.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.pruning.keep_at_least_n_per_class" title="cleanlab.pruning.keep_at_least_n_per_class"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keep_at_least_n_per_class</span></code></a>(prune_count_matrix, n)</p></td>
<td><p>Make sure every class has at least n examples after removing noise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.pruning.multiclass_crossval_predict" title="cleanlab.pruning.multiclass_crossval_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">multiclass_crossval_predict</span></code></a>(pyx, labels)</p></td>
<td><p>Returns an numpy 2D array of one-hot encoded multiclass predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.pruning.order_label_errors" title="cleanlab.pruning.order_label_errors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">order_label_errors</span></code></a>(label_errors_bool, psx, ...)</p></td>
<td><p>Sorts label errors by normalized margin.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.pruning.reduce_prune_counts" title="cleanlab.pruning.reduce_prune_counts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reduce_prune_counts</span></code></a>(prune_count_matrix[, ...])</p></td>
<td><p>Reduce (multiply) all prune counts (non-diagonal) by frac_noise and increase diagonal by the total amount reduced in each column to preserve column counts.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.pruning.get_noise_indices">
<span class="sig-prename descclassname"><span class="pre">cleanlab.pruning.</span></span><span class="sig-name descname"><span class="pre">get_noise_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_to_remove_per_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prune_by_noise_rate'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted_index_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/pruning.html#get_noise_indices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.pruning.get_noise_indices" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the indices of most likely (confident) label errors in s. The
number of indices returned is specified by frac_of_noise. When
frac_of_noise = 1.0, all “confident” estimated noise indices are returned.
* If you encounter the error ‘psx is not defined’, try setting n_jobs = 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A binary vector of labels, s, which may contain mislabeling. “s” denotes
the noisy label instead of tilde(y), for ASCII encoding reasons.</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(s=k|x) is a matrix with K (noisy) probabilities for each of the N
examples x.
This is the probability distribution over all K classes, for each
example, regarding whether the example has label s==k P(s=k|x).
psx should have been computed using 3+ fold cross-validation.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(y=k_y|s=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from psx and s.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">int)</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">None)</span></code>) – A K,K integer matrix of count(s=k, y=k). Estimates a a confident
subset of the joint distribution of the noisy and true labels P_{s,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (s=j, y=k) classes.</p></li>
<li><p><strong>frac_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – When frac_of_noise = 1.0, return all “confident” estimated noise indices.
Value in range (0, 1] that determines the fraction of noisy example
indices to return based on the following formula for example class k.
frac_of_noise * number_of_mislabeled_examples_in_class_k, or equivalently
frac_of_noise * inverse_noise_rate_class_k * num_examples_with_s_equal_k</p></li>
<li><p><strong>num_to_remove_per_class</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">length</span> <span class="pre">K</span> <span class="pre">(#</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes)</span></code>) – <p>e.g. if K = 3, num_to_remove_per_class = [5, 0, 1] would return
the indices of the 5 most likely mislabeled examples in class s = 0,
and the most likely mislabeled example in class s = 1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Only set this parameter if <code class="docutils literal notranslate"><span class="pre">prune_method</span> <span class="pre">==</span> <span class="pre">'prune_by_class'</span></code>
You may use with <code class="docutils literal notranslate"><span class="pre">prune_method</span> <span class="pre">==</span> <span class="pre">'prune_by_noise_rate'</span></code>, but
if <code class="docutils literal notranslate"><span class="pre">num_to_remove_per_class</span> <span class="pre">==</span> <span class="pre">k</span></code>, then either k-1, k, or k+1
examples may be removed for any class. This is because noise rates
are floats, and rounding may cause a one-off. If you need exactly
‘k’ examples removed from every class, you should use <code class="docutils literal notranslate"><span class="pre">'prune_by_class'</span></code></p>
</div>
</p></li>
<li><p><strong>prune_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(default</span></code>: <code class="docutils literal notranslate"><span class="pre">'prune_by_noise_rate'</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code>) – Possible Values: ‘prune_by_class’, ‘prune_by_noise_rate’, or ‘both’.
Method used for pruning.
1. ‘prune_by_noise_rate’: works by removing examples with
<em>high probability</em> of being mislabeled for every non-diagonal
in the prune_counts_matrix (see pruning.py).
2. ‘prune_by_class’: works by removing the examples with <em>smallest
probability</em> of belonging to their given class label for every class.
3. ‘both’: Finds the examples satisfying (1) AND (2) and
removes their set conjunction.</p></li>
<li><p><strong>sorted_index_method</strong> (<code class="docutils literal notranslate"><span class="pre">{:obj:`None`,</span> <span class="pre">:obj:`prob_given_label`,</span> <span class="pre">:obj:`normalized_margin`}</span></code>) – If None, returns a boolean mask (true if example at index is label error)
If not None, returns an array of the label error indices
(instead of a bool mask) where error indices are ordered by the either:
<code class="docutils literal notranslate"><span class="pre">'normalized_margin'</span> <span class="pre">:=</span> <span class="pre">normalized</span> <span class="pre">margin</span> <span class="pre">(p(s</span> <span class="pre">=</span> <span class="pre">k)</span> <span class="pre">-</span> <span class="pre">max(p(s</span> <span class="pre">!=</span> <span class="pre">k)))</span></code>
<code class="docutils literal notranslate"><span class="pre">'prob_given_label'</span> <span class="pre">:=</span> <span class="pre">[psx[i][labels[i]]</span> <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">label_errors_idx]</span></code></p></li>
<li><p><strong>multi_label</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, s should be an iterable (e.g. list) of iterables, containing a
list of labels for each example, instead of just a single label.</p></li>
<li><p><strong>n_jobs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(Windows</span> <span class="pre">users</span> <span class="pre">may</span> <span class="pre">see</span> <span class="pre">a</span> <span class="pre">speed-up</span> <span class="pre">with</span> <span class="pre">n_jobs</span> <span class="pre">=</span> <span class="pre">1)</span></code>) – Number of processing threads used by multiprocessing. Default None
sets to the number of processing threads on your CPU.
Set this to 1 to REMOVE parallel processing (if its causing issues).</p></li>
<li><p><strong>verbose</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – If 0, no print statements. If 1, prints when multiprocessing happens.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.pruning.keep_at_least_n_per_class">
<span class="sig-prename descclassname"><span class="pre">cleanlab.pruning.</span></span><span class="sig-name descname"><span class="pre">keep_at_least_n_per_class</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prune_count_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/pruning.html#keep_at_least_n_per_class"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.pruning.keep_at_least_n_per_class" title="Permalink to this definition">#</a></dt>
<dd><p>Make sure every class has at least n examples after removing noise.
Functionally, increase each column, increases the diagonal term #(y=k,s=k)
of prune_count_matrix until it is at least n, distributing the amount
increased by subtracting uniformly from the rest of the terms in the
column. When frac_of_noise = 1.0, return all “confidently” estimated
noise indices, otherwise this returns frac_of_noise fraction of all
the noise counts, with diagonal terms adjusted to ensure column
totals are preserved.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prune_count_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A counts of mislabeled examples in every class. For this function.
NOTE prune_count_matrix is transposed relative to confident_joint.</p></li>
<li><p><strong>n</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of examples to make sure are left in each class.</p></li>
<li><p><strong>frac_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – When frac_of_noise = 1.0, return all estimated noise indices.
Value in range (0, 1] that determines the fraction of noisy example
indices to return based on the following formula for example class k.
frac_of_noise * number_of_mislabeled_examples_in_class_k, or
frac_of_noise * inverse_noise_rate_class_k * num_examples_s_equal_k</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>prune_count_matrix</strong> – Number of examples to remove from each class, for every other class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.pruning.multiclass_crossval_predict">
<span class="sig-prename descclassname"><span class="pre">cleanlab.pruning.</span></span><span class="sig-name descname"><span class="pre">multiclass_crossval_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pyx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/pruning.html#multiclass_crossval_predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.pruning.multiclass_crossval_predict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an numpy 2D array of one-hot encoded
multiclass predictions. Each row in the array
provides the predictions for a particular example.
The boundary condition used to threshold predictions
is computed by maximizing the F1 ROC curve.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pyx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a NxK matrix with K probs for each of N examples.
This is the probability distribution over all K classes, for each
pyx should have been computed out of sample (holdout or crossval).</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">lists</span> <span class="pre">(length</span> <span class="pre">N)</span></code>) – These are multiclass labels. Each list in the list contains all the
labels for that example.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.pruning.order_label_errors">
<span class="sig-prename descclassname"><span class="pre">cleanlab.pruning.</span></span><span class="sig-name descname"><span class="pre">order_label_errors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_errors_bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sorted_index_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normalized_margin'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/pruning.html#order_label_errors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.pruning.order_label_errors" title="Permalink to this definition">#</a></dt>
<dd><p>Sorts label errors by normalized margin.
See <a class="reference external" href="https://arxiv.org/pdf/1810.05369.pdf">https://arxiv.org/pdf/1810.05369.pdf</a> (eqn 2.2)
eg. normalized_margin = prob_label - max_prob_not_label</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_errors_bool</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(bool)</span></code>) – Contains True if the index of labels is an error, o.w. false</p></li>
<li><p><strong>psx</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(s=k|x) is a matrix with K probabilities for all N examples x.
This is the probability distribution over all K classes, for each
example, regarding whether the example has label s==k P(s=k|x). psx
should computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A binary vector of labels, which may contain label errors.</p></li>
<li><p><strong>sorted_index_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">[``</span></code>’normalized_margin’<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``'prob_given_label'</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">]</span></code>) – <dl class="simple">
<dt>Method to order label error indices (instead of a bool mask), either:</dt><dd><p>’normalized_margin’ := normalized margin (p(s = k) - max(p(s != k)))
‘prob_given_label’ := [psx[i][labels[i]] for i in label_errors_idx]</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>label_errors_idx</strong> – Return the index integers of the label errors, ordered by
the normalized margin.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(int)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.pruning.reduce_prune_counts">
<span class="sig-prename descclassname"><span class="pre">cleanlab.pruning.</span></span><span class="sig-name descname"><span class="pre">reduce_prune_counts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prune_count_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/pruning.html#reduce_prune_counts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.pruning.reduce_prune_counts" title="Permalink to this definition">#</a></dt>
<dd><p>Reduce (multiply) all prune counts (non-diagonal) by frac_noise and
increase diagonal by the total amount reduced in each column to
preserve column counts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prune_count_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A counts of mislabeled examples in every class. For this function, it
does not matter what the rows or columns are, but the diagonal terms
reflect the number of correctly labeled examples.</p></li>
<li><p><strong>frac_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – When frac_of_noise = 1.0, return all estimated noise indices.
Value in range (0, 1] that determines the fraction of noisy example
indices to return based on the following formula for example class k.
frac_of_noise * number_of_mislabeled_examples_in_class_k, or
frac_of_noise * inverse_noise_rate_class_k * num_examples_s_equal_k.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.util">
<span id="utilities"></span><h1>Utilities<a class="headerlink" href="#module-cleanlab.util" title="Permalink to this headline">#</a></h1>
<p><strong>Classes:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.VersionWarning" title="cleanlab.util.VersionWarning"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VersionWarning</span></code></a>(warning_str, ...)</p></td>
<td><p>Functor that calls _python_version_is_compatible and manages the state of the bool variable warning_already_issued to make sure the same warning is never displayed multiple times.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.assert_inputs_are_valid" title="cleanlab.util.assert_inputs_are_valid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assert_inputs_are_valid</span></code></a>(X, s[, psx])</p></td>
<td><p>Checks that X, s, and psx are correctly formatted</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.clip_noise_rates" title="cleanlab.util.clip_noise_rates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_noise_rates</span></code></a>(noise_matrix)</p></td>
<td><p>Clip all noise rates to proper range [0,1), but do not modify the diagonal terms because they are not noise rates.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.clip_values" title="cleanlab.util.clip_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip_values</span></code></a>(x[, low, high, new_sum])</p></td>
<td><p>Clip all values in p to range [low,high].</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.confusion_matrix" title="cleanlab.util.confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a>(true, pred)</p></td>
<td><p>Implements a confusion matrix for true labels and predicted labels.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.estimate_pu_f1" title="cleanlab.util.estimate_pu_f1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_pu_f1</span></code></a>(s, prob_s_eq_1)</p></td>
<td><p>Computes Claesen's estimate of f1 in the pulearning setting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.int2onehot" title="cleanlab.util.int2onehot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int2onehot</span></code></a>(labels)</p></td>
<td><p>Convert list of lists to a onehot matrix for multi-labels</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.onehot2int" title="cleanlab.util.onehot2int"><code class="xref py py-obj docutils literal notranslate"><span class="pre">onehot2int</span></code></a>(onehot_matrix)</p></td>
<td><p>Convert a onehot matrix for multi-labels to a list of lists of ints</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.print_inverse_noise_matrix" title="cleanlab.util.print_inverse_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_inverse_noise_matrix</span></code></a>(inverse_noise_matrix)</p></td>
<td><p>Pretty prints the inverse noise matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.print_joint_matrix" title="cleanlab.util.print_joint_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_joint_matrix</span></code></a>(joint_matrix[, round_places])</p></td>
<td><p>Pretty prints the joint label noise matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.print_noise_matrix" title="cleanlab.util.print_noise_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_noise_matrix</span></code></a>(noise_matrix[, round_places])</p></td>
<td><p>Pretty prints the noise matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.print_square_matrix" title="cleanlab.util.print_square_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_square_matrix</span></code></a>(matrix[, left_name, ...])</p></td>
<td><p>Pretty prints a matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.remove_noise_from_class" title="cleanlab.util.remove_noise_from_class"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remove_noise_from_class</span></code></a>(noise_matrix, ...)</p></td>
<td><p>A helper function in the setting of PU learning.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.round_preserving_row_totals" title="cleanlab.util.round_preserving_row_totals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">round_preserving_row_totals</span></code></a>(confident_joint)</p></td>
<td><p>Rounds confident_joint cj to type int while preserving the totals of reach row.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.util.round_preserving_sum" title="cleanlab.util.round_preserving_sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">round_preserving_sum</span></code></a>(iterable)</p></td>
<td><p>Rounds an iterable of floats while retaining the original summed value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.value_counts" title="cleanlab.util.value_counts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_counts</span></code></a>(x)</p></td>
<td><p>Returns an np.array of shape (K, 1), with the value counts for every unique item in the labels list/array, where K is the number of unique entries in labels.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py class">
<dt class="sig sig-object py" id="cleanlab.util.VersionWarning">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">VersionWarning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">warning_str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_of_compatible_versions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#VersionWarning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.VersionWarning" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Functor that calls _python_version_is_compatible
and manages the state of the bool variable
warning_already_issued to make sure the same warning
is never displayed multiple times.</p>
<p><strong>Methods:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.util.VersionWarning.is_compatible" title="cleanlab.util.VersionWarning.is_compatible"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_compatible</span></code></a>()</p></td>
<td><p></p></td>
</tr>
</tbody>
</table></div>
<dl class="py method">
<dt class="sig sig-object py" id="cleanlab.util.VersionWarning.is_compatible">
<span class="sig-name descname"><span class="pre">is_compatible</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#VersionWarning.is_compatible"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.VersionWarning.is_compatible" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.assert_inputs_are_valid">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">assert_inputs_are_valid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">psx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#assert_inputs_are_valid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.assert_inputs_are_valid" title="Permalink to this definition">#</a></dt>
<dd><p>Checks that X, s, and psx
are correctly formatted</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.clip_noise_rates">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">clip_noise_rates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#clip_noise_rates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.clip_noise_rates" title="Permalink to this definition">#</a></dt>
<dd><p>Clip all noise rates to proper range [0,1), but
do not modify the diagonal terms because they are not
noise rates.</p>
<p>ASSUMES noise_matrix columns sum to 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probablity matrix containing the fraction of
examples in every class, labeled as every other class.
Diagonal terms are not noise rates, but are consistency P(s=k|y=k)
Assumes columns of noise_matrix sum to 1</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.clip_values">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">clip_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_sum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#clip_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.clip_values" title="Permalink to this definition">#</a></dt>
<dd><p>Clip all values in p to range [low,high].
Preserves sum of x.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – An array / list of values to be clipped.</p></li>
<li><p><strong>low</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – values in x greater than ‘low’ are clipped to this value</p></li>
<li><p><strong>high</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – values in x greater than ‘high’ are clipped to this value</p></li>
<li><p><strong>new_sum</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – normalizes x after clipping to sum to new_sum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – A list of clipped values, summing to the same sum as x.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.confusion_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">confusion_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#confusion_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.confusion_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Implements a confusion matrix for true labels
and predicted labels. true and pred MUST BE the same length
and have the same distinct set of class labels represtented.</p>
<dl class="simple">
<dt>Results are identical (and similar computation time) to:</dt><dd><p>“sklearn.metrics.confusion_matrix”</p>
</dd>
</dl>
<p>However, this function avoids the dependency on sklearn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">1d</span></code>) – Contains labels.
Assumes s and y contains the same distinct set of labels.</p></li>
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">1d</span></code>) – Contains labels.
Assumes s and y contains the same distinct set of labels.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>confusion_matrix</strong> – matrix of confusion counts with true on rows and pred on columns.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(2D)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.estimate_pu_f1">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">estimate_pu_f1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_s_eq_1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#estimate_pu_f1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.estimate_pu_f1" title="Permalink to this definition">#</a></dt>
<dd><p>Computes Claesen’s estimate of f1 in the pulearning setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code>) – Binary label (whether each element is labeled or not) in pu learning.</p></li>
<li><p><strong>prob_s_eq_1</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code>) – The probability, for each example, whether it is s==1 P(s==1|x)</p></li>
<li><p><strong>(</strong><strong>float</strong><strong>)</strong> (<em>Output</em>) – </p></li>
<li><p><strong>------</strong> – </p></li>
<li><p><strong>setting.</strong> (<em>Claesen's estimate for f1 in the pulearning</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.int2onehot">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">int2onehot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#int2onehot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.int2onehot" title="Permalink to this definition">#</a></dt>
<dd><p>Convert list of lists to a onehot matrix for multi-labels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">lists</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">integers</span></code>) – e.g. [[0,1], [3], [1,2,3], [1], [2]]
All integers from 0,1,…,K-1 must be represented.</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.onehot2int">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">onehot2int</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onehot_matrix</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#onehot2int"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.onehot2int" title="Permalink to this definition">#</a></dt>
<dd><p>Convert a onehot matrix for multi-labels to a list of lists of ints</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>onehot_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">2D</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">0s</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">1s</span></code>) – A one hot encoded matrix representation of multi-labels.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>labels</strong> – e.g. [[0,1], [3], [1,2,3], [1], [2]]
All integers from 0,1,…,K-1 must be represented.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">lists</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">integers</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.print_inverse_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">print_inverse_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_places</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#print_inverse_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.print_inverse_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Pretty prints the inverse noise matrix.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.print_joint_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">print_joint_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">joint_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_places</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#print_joint_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.print_joint_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Pretty prints the joint label noise matrix.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.print_noise_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">print_noise_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_places</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#print_noise_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.print_noise_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Pretty prints the noise matrix.</p>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.print_square_matrix">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">print_square_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">left_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'s'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'y'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'</span> <span class="pre">A</span> <span class="pre">square</span> <span class="pre">matrix'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">short_title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'s,y'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round_places</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#print_square_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.print_square_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Pretty prints a matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – the matrix to be printed</p></li>
<li><p><strong>left_name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – the name of the variable on the left of the matrix</p></li>
<li><p><strong>top_name</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – the name of the variable on the top of the matrix</p></li>
<li><p><strong>title</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Prints this string above the printed square matrix.</p></li>
<li><p><strong>short_title</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – A short title (6 characters or less) like P(s|y) or P(s,y).</p></li>
<li><p><strong>round_places</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Number of decimals to show for each matrix value.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.remove_noise_from_class">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">remove_noise_from_class</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_without_noise</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#remove_noise_from_class"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.remove_noise_from_class" title="Permalink to this definition">#</a></dt>
<dd><p>A helper function in the setting of PU learning.
Sets all P(s=class_without_noise|y=any_other_class) = 0
in noise_matrix for pulearning setting, where we have
generalized the positive class in PU learning to be any
class of choosing, denoted by class_without_noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probablity matrix of the form P(s=k_s|y=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>class_without_noise</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Integer value of the class that has no noise. Traditionally,
this is 1 (positive) for PU learning.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.round_preserving_row_totals">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">round_preserving_row_totals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#round_preserving_row_totals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.round_preserving_row_totals" title="Permalink to this definition">#</a></dt>
<dd><p>Rounds confident_joint cj to type int
while preserving the totals of reach row.
Assumes that cj is a 2D np.array of type float.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">2D</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>) – See compute_confident_joint docstring for details.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>confident_joint</strong> – Rounded to int while preserving row totals.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">2D</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K,K)</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.round_preserving_sum">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">round_preserving_sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#round_preserving_sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.round_preserving_sum" title="Permalink to this definition">#</a></dt>
<dd><p>Rounds an iterable of floats while retaining the original summed value.
The name of each parameter is required. The type and description of each
parameter is optional, but should be included if not obvious.</p>
<p>The while loop in this code was adapted from:
<a class="reference external" href="https://github.com/cgdeboer/iteround">https://github.com/cgdeboer/iteround</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>iterable</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – An iterable of floats</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The iterable rounded to int, preserving sum.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.util.value_counts">
<span class="sig-prename descclassname"><span class="pre">cleanlab.util.</span></span><span class="sig-name descname"><span class="pre">value_counts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/util.html#value_counts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.util.value_counts" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an np.array of shape (K, 1), with the
value counts for every unique item in the labels list/array,
where K is the number of unique entries in labels.</p>
<dl class="simple">
<dt>Why this matters? Here is an example:</dt><dd><p>x = [np.random.randint(0,100) for i in range(100000)]</p>
</dd>
<dt>%timeit np.bincount(x)</dt><dd><p>–Result: 100 loops, best of 3: 3.9 ms per loop</p>
</dd>
<dt>%timeit np.unique(x, return_counts=True)[1]</dt><dd><p>–Result: 100 loops, best of 3: 7.47 ms per loop</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(one</span> <span class="pre">dimensional)</span></code>) – A list of discrete objects, like lists or strings, for
example, class labels ‘y’ when training a classifier.
e.g. [“dog”,”dog”,”cat”] or [1,2,0,1,1,0,2]</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-cleanlab.polyplex">
<span id="polyplex"></span><h1>Polyplex<a class="headerlink" href="#module-cleanlab.polyplex" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.polyplex.joint_bounds" title="cleanlab.polyplex.joint_bounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">joint_bounds</span></code></a>(py)</p></td>
<td><p>Computes three lists: noise_matrix_trace, joint_trace_min, joint_trace_max that when plotted, the noise_matrix_trace values represent x-values and the joint_trace_min and joint_trace_max values represent the y-value min and maximium ranges.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.polyplex.joint_min_max" title="cleanlab.polyplex.joint_min_max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">joint_min_max</span></code></a>(noise_matrix_trace, py)</p></td>
<td><p>Computes the min and max bounds on the trace(P_{s,y}), the trace of the joint distribution, given the trace of the noise matrix and p(y).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.polyplex.slope_intercept" title="cleanlab.polyplex.slope_intercept"><code class="xref py py-obj docutils literal notranslate"><span class="pre">slope_intercept</span></code></a>(point1, point2)</p></td>
<td><p>Returns the slope and intercept between point1 and point2.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.polyplex.joint_bounds">
<span class="sig-prename descclassname"><span class="pre">cleanlab.polyplex.</span></span><span class="sig-name descname"><span class="pre">joint_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">py</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/polyplex.html#joint_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.polyplex.joint_bounds" title="Permalink to this definition">#</a></dt>
<dd><p>Computes three lists: noise_matrix_trace, joint_trace_min, joint_trace_max that when
plotted, the noise_matrix_trace values represent x-values and the joint_trace_min and
joint_trace_max values represent the y-value min and maximium ranges. Together, these
three lists fully characterize the polyplex.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each true, hidden class label, P(y = k)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">lists</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">floats</span> <span class="pre">(noise_matrix_trace</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">joint_trace_min</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">joint_trace_max)</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">each</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">length</span> <span class="pre">K+1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">where</span> <span class="pre">K</span> <span class="pre">=</span> <span class="pre">len(py).</span> <span class="pre">When</span> <span class="pre">plotted</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">noise_matrix_trace</span> <span class="pre">values</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">represent</span> <span class="pre">x-values</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">joint_trace_min</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">joint_trace_max</span> <span class="pre">values</span> <span class="pre">represent</span> <span class="pre">the</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">y-value</span> <span class="pre">min</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">maximium</span> <span class="pre">ranges.</span> <span class="pre">These</span> <span class="pre">three</span> <span class="pre">lists</span> <span class="pre">fully</span> <span class="pre">characterize</span> <span class="pre">the</span> <span class="pre">polyplex.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.polyplex.joint_min_max">
<span class="sig-prename descclassname"><span class="pre">cleanlab.polyplex.</span></span><span class="sig-name descname"><span class="pre">joint_min_max</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">noise_matrix_trace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/polyplex.html#joint_min_max"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.polyplex.joint_min_max" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the min and max bounds on the trace(P_{s,y}), the trace of the
joint distribution, given the trace of the noise matrix and p(y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>noise_matrix_trace</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – The sum of the diagonals of the noise matrix P(s = k’ | y = k)</p></li>
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">1))</span></code>) – The fraction (prior probability) of each true, hidden class label, P(y = k)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">two</span> <span class="pre">floats</span> <span class="pre">(y_min</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">y_max)</span> <span class="pre">representing</span> <span class="pre">the</span> <span class="pre">bounds</span> <span class="pre">on</span> <span class="pre">the</span> <span class="pre">trace</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">joint.</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.polyplex.slope_intercept">
<span class="sig-prename descclassname"><span class="pre">cleanlab.polyplex.</span></span><span class="sig-name descname"><span class="pre">slope_intercept</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">point1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">point2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cleanlab/polyplex.html#slope_intercept"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.polyplex.slope_intercept" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the slope and intercept between point1 and point2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>point1</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>) – e.g. (1.3, 4)</p></li>
<li><p><strong>point2</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">tuple(slope</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">intercept)</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="models">
<h1>Models<a class="headerlink" href="#models" title="Permalink to this headline">#</a></h1>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="cleanlab.models.html">CIFAR CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="cleanlab.models.html#module-cleanlab.models.mnist_pytorch">MNIST PyTorch</a></li>
</ul>
</div>
</div>
 

        </article>
      </div>
      <footer>
        

        <div class="related-pages">
          <a class="next-page" href="cleanlab.models.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">CIFAR CNN</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="notebooks/Audio_Tut.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Audio Classification with Cleanlab and LightGBM</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
         
<script type="text/javascript">
  function genDistMsg() {
    var element = document.getElementsByClassName("left-details");
    element[0].insertAdjacentHTML('afterbegin', '<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.');
  }

  genDistMsg();
</script>


      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    </body>
</html>