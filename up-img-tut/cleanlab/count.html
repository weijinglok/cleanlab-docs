<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="rank" href="rank.html" /><link rel="prev" title="classification" href="classification.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png"/><meta name="generator" content="sphinx-4.4.0, furo 2022.02.23"/>
        <title>count - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=3c656993158f05539f962c5cea52a5e6c184bb8c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">cleanlab</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/image.html">Image Classification with PyTorch and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/text.html">Text Classification with TensorFlow, Keras, and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tabular.html">Classification with Tabular Data using Scikit-Learn and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/audio.html">Audio Classification with SpeechBrain and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pred_probs_cross_val.html">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="classification.html">classification</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise_generation.html">noise_generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="coteaching.html">coteaching</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="example_models/index.html">example_models</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="example_models/cifar_cnn.html">cifar.cnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_models/mnist_pytorch.html">mnist_pytorch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="internal/label_quality_utils.html">label_quality_utils</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/cleanlab-docs/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/cleanlab-docs/master/"
                >developer</a
            >
        </li>
    </ul>
</div>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
           

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML = 
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number)) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">up-img-tut</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 <div class="section" id="module-cleanlab.count">
<span id="count"></span><h1>count<a class="headerlink" href="#module-cleanlab.count" title="Permalink to this headline">#</a></h1>
<p><strong>Functions:</strong></p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.calibrate_confident_joint" title="cleanlab.count.calibrate_confident_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calibrate_confident_joint</span></code></a>(confident_joint, ...)</p></td>
<td><p>Calibrates any confident joint estimate P(label=i, true_label=j) such that np.sum(cj) == len(labels) and np.sum(cj, axis = 1) == np.bincount(labels).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.compute_confident_joint" title="cleanlab.count.compute_confident_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_confident_joint</span></code></a>(labels, pred_probs, *)</p></td>
<td><p>Estimates P(labels,y), the confident counts of the latent joint distribution of true and noisy labels using observed labels and predicted probabilities pred_probs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.converge_estimates" title="cleanlab.count.converge_estimates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">converge_estimates</span></code></a>(ps, py, noise_matrix, ...)</p></td>
<td><p>Computes py := P(true_label=k) and both noise_matrix and inverse_noise_matrix, by numerically converging ps := P(labels=k), py, and the noise matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.estimate_confident_joint_and_cv_pred_proba" title="cleanlab.count.estimate_confident_joint_and_cv_pred_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_confident_joint_and_cv_pred_proba</span></code></a>(X, ...)</p></td>
<td><p>Estimates P(labels,y), the confident counts of the latent joint distribution of true and noisy labels using observed labels and predicted probabilities pred_probs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.estimate_cv_predicted_probabilities" title="cleanlab.count.estimate_cv_predicted_probabilities"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_cv_predicted_probabilities</span></code></a>(X, labels)</p></td>
<td><p>This function computes the out-of-sample predicted probability [P(label=k|x)] for every example in X using cross validation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.estimate_joint" title="cleanlab.count.estimate_joint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_joint</span></code></a>(labels[, pred_probs, ...])</p></td>
<td><p>Estimates the joint distribution of label noise P(label=i, true_label=j) guaranteed to</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.estimate_latent" title="cleanlab.count.estimate_latent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_latent</span></code></a>(confident_joint, labels, *)</p></td>
<td><p>Computes the latent prior p(y), the noise matrix P(labels|y) and the inverse noise matrix P(y|labels) from the <cite>confident_joint</cite> count(labels, y).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.estimate_noise_matrices" title="cleanlab.count.estimate_noise_matrices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_noise_matrices</span></code></a>(X, labels[, clf, ...])</p></td>
<td><p>Estimates the noise_matrix of shape (K, K).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.estimate_py_and_noise_matrices_from_probabilities" title="cleanlab.count.estimate_py_and_noise_matrices_from_probabilities"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_py_and_noise_matrices_from_probabilities</span></code></a>(...)</p></td>
<td><p>Computes the confident counts estimate of latent variables py and the noise rates using observed labels and predicted probabilities, pred_probs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.estimate_py_noise_matrices_and_cv_pred_proba" title="cleanlab.count.estimate_py_noise_matrices_and_cv_pred_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_py_noise_matrices_and_cv_pred_proba</span></code></a>(X, ...)</p></td>
<td><p>This function computes the out-of-sample predicted probability P(label=k|x) for every example x in X using cross validation while also computing the confident counts noise rates within each cross-validated subset and returning the average noise rate across all examples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cleanlab.count.get_confident_thresholds" title="cleanlab.count.get_confident_thresholds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_confident_thresholds</span></code></a>(labels, pred_probs)</p></td>
<td><p>Returns expected (average) "self-confidence" for each class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cleanlab.count.num_label_issues" title="cleanlab.count.num_label_issues"><code class="xref py py-obj docutils literal notranslate"><span class="pre">num_label_issues</span></code></a>(labels, pred_probs[, ...])</p></td>
<td><p>Estimates the number of label issues in <cite>labels</cite>.</p></td>
</tr>
</tbody>
</table></div>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.calibrate_confident_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">calibrate_confident_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#calibrate_confident_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.calibrate_confident_joint" title="Permalink to this definition">#</a></dt>
<dd><p>Calibrates any confident joint estimate P(label=i, true_label=j) such that
np.sum(cj) == len(labels) and np.sum(cj, axis = 1) == np.bincount(labels).</p>
<p>In other words, this function forces the confident joint to have the
true noisy prior p(labels) (summed over columns for each row) and also
forces the confident joint to add up to the total number of examples.</p>
<p>This method makes the confident joint a valid counts estimate
of the actual joint of noisy and true labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – A K,K integer matrix of count(label=k, true_label=k). Estimates a confident subset of
the joint distribution of the noisy and true labels P_{labels,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (label=j, true_label=k) classes.</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>multi_label</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, labels should be an iterable (e.g. list) of iterables, containing a
list of labels for each example, instead of just a single label.
The MAJOR DIFFERENCE in how this is calibrated versus single_label, is the total number of
errors considered is based on the number of labels, not the number of examples. So, the
calibrated confident_joint will sum to the number of total labels.
The multi-label setting supports classification tasks where an example has 1 or more labels.
Example of a multi-labeled <cite>labels</cite> input: [[0,1], [1], [0,2], [0,1,2], [0], [1], …]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">float</span> <span class="pre">representing</span> <span class="pre">a</span> <span class="pre">valid</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">estimate</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">joint</span> <span class="pre">COUNTS</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">noisy</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">true</span> <span class="pre">labels.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.compute_confident_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">compute_confident_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_probs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_indices_of_off_diagonals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#compute_confident_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.compute_confident_joint" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates P(labels,y), the confident counts of the latent
joint distribution of true and noisy labels
using observed labels and predicted probabilities pred_probs.</p>
<p>This estimate is called the confident joint.</p>
<p>When calibrate = True, this method returns an estimate of
the latent true joint counts of noisy and true labels.</p>
<p>Important! This function assumes that pred_probs are out-of-sample
holdout probabilities. This can be done with cross validation. If
the probabilities are not computed out-of-sample, overfitting may occur.</p>
<p>This function estimates the joint of shape (K, K). This is the
confident counts of examples in every class, labeled as every other class.</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, the estimate is within 1 percent of the truth.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>pred_probs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K model-predicted probabilities.
Each row of this matrix corresponds to an example <cite>x</cite> and contains the model-predicted
probabilities that <cite>x</cite> belongs to each possible class.
The columns must be ordered such that these probabilities correspond to class 0,1,2,…
<cite>pred_probs</cite> must be out-of-sample and should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>K</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">None)</span></code>) – Number of unique classes. Calculated as len(np.unique(labels)) when K == None</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(label^=k|label=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having true_label = k. This is
not used for filtering/pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(label=i, true_label=j) such that
np.sum(cj) == len(labels) and np.sum(cj, axis = 1) == np.bincount(labels).</p></li>
<li><p><strong>multi_label</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, labels should be an iterable (e.g. list) of iterables, containing a
list of labels for each example, instead of just a single label.
The multi-label setting supports classification tasks where an example has 1 or more labels.
Example of a multi-labeled <cite>labels</cite> input: [[0,1], [1], [0,2], [0,1,2], [0], [1], …]</p></li>
<li><p><strong>return_indices_of_off_diagonals</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true returns indices of examples that were counted in off-diagonals
of confident joint as a baseline proxy for the label issues. This
sometimes works as well as filter.find_label_issues(confident_joint).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>We provide a for-loop based simplification of the confident joint
below. This implementation is not efficient, not used in practice, and
not complete, but covers the gist of how the confident joint is computed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Confident examples are those that we are confident have true_label = k</span>
<span class="c1"># Estimate (K, K) matrix of confident examples with label = k_s and true_label = k_y</span>
<span class="n">cj_ish</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span> <span class="c1"># k_s is the class value k of noisy labels `s`</span>
    <span class="k">for</span> <span class="n">k_y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span> <span class="c1"># k_y is the (guessed) class k of true_label k_y</span>
        <span class="n">cj_ish</span><span class="p">[</span><span class="n">k_s</span><span class="p">][</span><span class="n">k_y</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">pred_probs</span><span class="p">[:,</span><span class="n">k_y</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">thresholds</span><span class="p">[</span><span class="n">k_y</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1e-8</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">k_s</span><span class="p">))</span>
</pre></div>
</div>
<p>The following is a vectorized (but non-parallelized) implementation of the
confident joint, again slow, using for-loops/simplified for understanding.
This implementation is 100% accurate, it’s just not optimized for speed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">confident_joint</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">):</span>
    <span class="n">s_label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">confident_bins</span> <span class="o">=</span> <span class="n">row</span> <span class="o">&gt;=</span> <span class="n">thresholds</span> <span class="o">-</span> <span class="mf">1e-6</span>
    <span class="n">num_confident_bins</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">confident_bins</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_confident_bins</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">confident_joint</span><span class="p">[</span><span class="n">s_label</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">confident_bins</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">num_confident_bins</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">confident_joint</span><span class="p">[</span><span class="n">s_label</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">row</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.converge_estimates">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">converge_estimates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inverse_noise_matrix</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inv_noise_matrix_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_matrix_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#converge_estimates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.converge_estimates" title="Permalink to this definition">#</a></dt>
<dd><p>Computes py := P(true_label=k) and both noise_matrix and inverse_noise_matrix,
by numerically converging ps := P(labels=k), py, and the noise matrices.</p>
<p>Forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p>
<p>py := P(true_label=k) and the inverse noise matrix P(true_label=k_y|label=k_s) specify one
another, meaning one can be computed from the other and vice versa.
When numerical discrepancy exists due to poor estimation, they can be made
to agree by repeatedly computing one from the other,
for some a certain number of iterations (3-10 works fine.)</p>
<p>Do not set iterations too high or performance will decrease as small
deviations will get perturbed over and over and potentially magnified.</p>
<p>Note that we have to first converge the inverse_noise_matrix and py,
then we can update the noise_matrix, then repeat. This is because the
inverse noise matrix depends on py (which is unknown/latent), but the
noise matrix depends on ps (which is known), so there will be no change in
the noise matrix if we recompute it when py and inverse_noise_matrix change.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ps</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The fraction (prior probability) of each observed, NOISY class P(labels = k).</p></li>
<li><p><strong>py</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">)</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">(1</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – The estimated fraction (prior probability) of each TRUE class P(true_label = k).</p></li>
<li><p><strong>noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(label=k_s|true_label=k_y) containing
the fraction of examples in every class, labeled as every other class.
Assumes columns of noise_matrix sum to 1.</p></li>
<li><p><strong>inverse_noise_matrix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">classes</span></code>) – A conditional probability matrix of the form P(true_label=k_y|labels=k_s) representing
the estimated fraction observed examples in each class k_s, that are
mislabeled examples from every other class k_y. If None, the
inverse_noise_matrix will be computed from pred_probs and labels.
Assumes columns of inverse_noise_matrix sum to 1.</p></li>
<li><p><strong>inv_noise_matrix_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(Default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">5)</span></code>) – Number of times to converge inverse noise matrix with py and noise mat.</p></li>
<li><p><strong>noise_matrix_iterations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(Default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">3)</span></code>) – Number of times to converge noise matrix with py and inverse noise mat.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Three</span> <span class="pre">np.arrays</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">form</span> <span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix)</span> <span class="pre">all</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">having</span> <span class="pre">numerical</span> <span class="pre">agreement</span> <span class="pre">in</span> <span class="pre">terms</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">their</span> <span class="pre">mathematical</span> <span class="pre">relations.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_confident_joint_and_cv_pred_proba">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_confident_joint_and_cv_pred_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_confident_joint_and_cv_pred_proba"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_confident_joint_and_cv_pred_proba" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates P(labels,y), the confident counts of the latent
joint distribution of true and noisy labels
using observed labels and predicted probabilities pred_probs.</p>
<p>The output of this function is a numpy array of shape (K, K).</p>
<p>Under certain conditions, estimates are exact, and in many
conditions, estimates are within one percent of actual.</p>
<p>Notes: There are two ways to compute the confident joint with pros/cons.
1. For each holdout set, we compute the confident joint, then sum them up.
2. Compute pred_proba for each fold, combine, compute the confident joint.
(1) is more accurate because it correctly computes thresholds for each fold
(2) is more accurate when you have only a little data because it computes
the confident joint using all the probabilities. For example if you had 100
examples, with 5-fold cross validation + uniform p(y) you would only have 20
examples to compute each confident joint for (1). Such small amounts of data
is bound to result in estimation errors. For this reason, we implement (2),
but we implement (1) as a commented out function at the end of this file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(label^=k|label=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having true_label = k. This is
not used for filtering/pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(label=i, true_label=j) such that
np.sum(cj) == len(labels) and np.sum(cj, axis = 1) == np.bincount(labels).</p></li>
<li><p><strong>clf_kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <em>default</em> = <code class="docutils literal notranslate"><span class="pre">{}</span></code>) – Optional keyword arguments to pass into <cite>clf</cite> fit() method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">two</span> <span class="pre">numpy</span> <span class="pre">array</span> <span class="pre">matrices</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">form</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">(joint</span> <span class="pre">counts</span> <span class="pre">matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">predicted</span> <span class="pre">probability</span> <span class="pre">matrix)</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_cv_predicted_probabilities">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_cv_predicted_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_cv_predicted_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_cv_predicted_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>This function computes the out-of-sample predicted
probability [P(label=k|x)] for every example in X using cross
validation. Output is a np.array of shape (N, K) where N is
the number of training examples and K is the number of classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">ints</span> <span class="pre">from</span> <span class="pre">[0,1,..,K-1]</span></code>) – A discrete vector of class labels which may or may not contain mislabeling.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>clf_kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <em>default</em> = <code class="docutils literal notranslate"><span class="pre">{}</span></code>) – Optional keyword arguments to pass into <cite>clf</cite> fit() method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>pred_probs</strong> – P(label=k|x) is a matrix with K model-predicted probabilities.
Each row of this matrix corresponds to an example <cite>x</cite> and contains the model-predicted
probabilities that <cite>x</cite> belongs to each possible class.
The columns must be ordered such that these probabilities correspond to class 0,1,2,…
<cite>pred_probs</cite> should have been computed using 3 (or higher) fold cross-validation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_joint">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_joint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_joint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_joint" title="Permalink to this definition">#</a></dt>
<dd><dl class="simple">
<dt>Estimates the joint distribution of label noise P(label=i, true_label=j) guaranteed to</dt><dd><ul class="simple">
<li><p>sum to 1</p></li>
<li><p>np.sum(joint_estimate, axis = 1) == p(labels)</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>docstring.</strong> (<em>See cleanlab.count.calibrate_confident_joint</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">np.array</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">float</span> <span class="pre">representing</span> <span class="pre">a</span> <span class="pre">valid</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">estimate</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">true</span> <span class="pre">joint</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">noisy</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">true</span> <span class="pre">labels.</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_latent">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_latent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_latent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_latent" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the latent prior p(y), the noise matrix P(labels|y) and the
inverse noise matrix P(y|labels) from the <cite>confident_joint</cite> count(labels, y). The
<cite>confident_joint</cite> estimated by <cite>compute_confident_joint</cite>
by counting confident examples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">int)</span></code>) – A K,K integer matrix of count(label=k, true_label=k). Estimates a confident subset
of the joint distribution of the noisy and true labels P_{labels,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (label=j, true_label=k) classes.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – <cite>py</cite> is shorthand for the <cite>class proportions (a.k.a prior) of the true labels</cite>
This method defines how to compute the latent prior p(true_label=k). Default is “cnt”.
“cnt” works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">tuple</span> <span class="pre">containing</span> <span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inv_noise_matrix).</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_noise_matrices">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_noise_matrices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_noise_matrices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_noise_matrices" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(label=k_s|true_label=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(label^=k|label). If an example has a predicted probability “greater” than
this threshold, it is counted as having true_label = k. This is
not used for filtering/pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>clf_kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <em>default</em> = <code class="docutils literal notranslate"><span class="pre">{}</span></code>) – Optional keyword arguments to pass into <cite>clf</cite> fit() method.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">A</span> <span class="pre">two-item</span> <span class="pre">tuple</span> <span class="pre">containing</span> <span class="pre">(noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inv_noise_matrix).</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_py_and_noise_matrices_from_probabilities">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_py_and_noise_matrices_from_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_probs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">calibrate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_py_and_noise_matrices_from_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_py_and_noise_matrices_from_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the confident counts
estimate of latent variables py and the noise rates
using observed labels and predicted probabilities, pred_probs.</p>
<p>Important! This function assumes that pred_probs are out-of-sample
holdout probabilities. This can be done with cross validation. If
the probabilities are not computed out-of-sample, overfitting may occur.</p>
<p>This function estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(label=k_s|true_label=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>pred_probs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K model-predicted probabilities.
Each row of this matrix corresponds to an example <cite>x</cite> and contains the model-predicted
probabilities that <cite>x</cite> belongs to each possible class.
The columns must be ordered such that these probabilities correspond to class 0,1,2,…
<cite>pred_probs</cite> should have been computed using 3 (or higher) fold cross-validation.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(label^=k|label=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having true_label = k. This is
not used for filtering/pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(true_label=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>calibrate</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span> <span class="pre">(default</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">True)</span></code>) – Calibrates confident joint estimate P(label=i, true_label=j) such that
np.sum(cj) == len(labels) and np.sum(cj, axis = 1) == np.bincount(labels).</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.estimate_py_noise_matrices_and_cv_pred_proba">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">estimate_py_noise_matrices_and_cv_pred_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LogisticRegression()</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cv_n_folds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">converge_latent_estimates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">py_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cnt'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clf_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#estimate_py_noise_matrices_and_cv_pred_proba"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.estimate_py_noise_matrices_and_cv_pred_proba" title="Permalink to this definition">#</a></dt>
<dd><p>This function computes the out-of-sample predicted
probability P(label=k|x) for every example x in X using cross
validation while also computing the confident counts noise
rates within each cross-validated subset and returning
the average noise rate across all examples.</p>
<p>This function estimates the noise_matrix of shape (K, K). This is the
fraction of examples in every class, labeled as every other class. The
noise_matrix is a conditional probability matrix for P(label=k_s|true_label=k_y).</p>
<p>Under certain conditions, estimates are exact, and in most
conditions, estimates are within one percent of the actual noise rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – Input feature matrix (N, D), 2D numpy array</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>clf</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.classifier</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">equivalent</span></code>) – Default classifier used is logistic regression. Assumes clf
has predict_proba() and fit() defined.</p></li>
<li><p><strong>cv_n_folds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – The number of cross-validation folds used to compute
out-of-sample probabilities for each example in X.</p></li>
<li><p><strong>thresholds</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">iterable</span> <span class="pre">(list</span></code> or <code class="xref py py-class docutils literal notranslate"><span class="pre">np.array)</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">shape</span> <span class="pre">(K</span></code>, 1)  or <code class="xref py py-class docutils literal notranslate"><span class="pre">(K,)</span></code>) – P(label^=k|label=k). If an example has a predicted probability “greater” than
this threshold, it is counted as having true_label = k. This is
not used for filtering/pruning, only for estimating the noise rates using
confident counts. This value should be between 0 and 1. Default is None.</p></li>
<li><p><strong>converge_latent_estimates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If true, forces numerical consistency of estimates. Each is estimated
independently, but they are related mathematically with closed form
equivalences. This will iteratively make them mathematically consistent.</p></li>
<li><p><strong>py_method</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span> <span class="pre">(Options</span></code>: <code class="xref py py-class docutils literal notranslate"><span class="pre">[``</span></code>”cnt”<code class="docutils literal notranslate"><span class="pre">,</span> <span class="pre">``"eqn"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal"</span></code>, <code class="docutils literal notranslate"><span class="pre">"marginal_ps"</span></code><code class="xref py py-class docutils literal notranslate"><span class="pre">])</span></code>) – How to compute the latent prior p(true_label=k). Default is “cnt” as it often
works well even when the noise matrices are estimated poorly by using
the matrix diagonals instead of all the probabilities.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span> <span class="pre">(default</span> <span class="pre">=</span> <span class="pre">None)</span></code>) – Set the default state of the random number generator used to split
the cross-validated folds. If None, uses np.random current random state.</p></li>
<li><p><strong>clf_kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>, <em>default</em> = <code class="docutils literal notranslate"><span class="pre">{}</span></code>) – Optional keyword arguments to pass into <cite>clf</cite> fit() method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">five</span> <span class="pre">numpy</span> <span class="pre">array</span> <span class="pre">matrices</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">form</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">(py</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">noise_matrix</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">inverse_noise_matrix,</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">joint</span> <span class="pre">count</span> <span class="pre">matrix</span> <span class="pre">i.e.</span> <span class="pre">confident</span> <span class="pre">joint</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">predicted</span> <span class="pre">probability</span> <span class="pre">matrix)</span></code></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.get_confident_thresholds">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">get_confident_thresholds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_probs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.array</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">numpy.array</span></span></span><a class="reference internal" href="../_modules/cleanlab/count.html#get_confident_thresholds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.get_confident_thresholds" title="Permalink to this definition">#</a></dt>
<dd><p>Returns expected (average) “self-confidence” for each class.</p>
<p>The confident class threshold for a class j is the expected (average) “self-confidence” for class j.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>pred_probs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – P(label=k|x) is a matrix with K model-predicted probabilities.
Each row of this matrix corresponds to an example x and contains the model-predicted
probabilities that x belongs to each possible class.
The columns must be ordered such that these probabilities correspond to class 0,1,2,…
<cite>pred_probs</cite> should have been computed using 3 (or higher) fold cross-validation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>confident_thresholds</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K,))</span></code></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="cleanlab.count.num_label_issues">
<span class="sig-prename descclassname"><span class="pre">cleanlab.count.</span></span><span class="sig-name descname"><span class="pre">num_label_issues</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confident_joint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cleanlab/count.html#num_label_issues"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cleanlab.count.num_label_issues" title="Permalink to this definition">#</a></dt>
<dd><p>Estimates the number of label issues in <cite>labels</cite>.</p>
<p>This method is <strong>more accurate</strong> than <cite>sum(find_label_issues())</cite> because its computed using only
the Trace(joint), ignoring all off-diagonals (used by <cite>find_label_issues</cite> and harder to
estimate). Here we sum over only diagonal elements in the joint (which have more data
are more constrained, and therefore easier to compute).</p>
<p>tl;dr - Use this method to get the most accurate estimate of number of label issues when you
don’t need the indices of the label issues. This is the canonical way to find errors
simply by combining a ranking/scoring function from <cite>rank.py</cite> with <cite>num_label_issues()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span></code>) – A discrete vector of noisy labels, i.e. some labels may be erroneous.
<em>Format requirements</em>: for dataset with K classes, labels must be in {0,1,…,K-1}.</p></li>
<li><p><strong>pred_probs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(N</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K))</span></code>) – <p>P(label=k|x) is a matrix with K model-predicted probabilities.
Each row of this matrix corresponds to an example <cite>x</cite> and contains the model-predicted
probabilities that <cite>x</cite> belongs to each possible class.
The columns must be ordered such that these probabilities correspond to class 0,1,2,…</p>
<p>CAUTION: <cite>pred_probs</cite> from your model must be out-of-sample!
You should never provide predictions on the same datapoints used to train the model,
as these will be overfit and unsuitable for finding label-errors.
To obtain out-of-sample predicted probabilities for every datapoint in your dataset, you can use cross-validation.
Alternatively it is ok if your model was trained on a separate dataset and you are only evaluating
labels in data that was previously held-out.</p>
</p></li>
<li><p><strong>confident_joint</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">np.array</span> <span class="pre">(shape</span> <span class="pre">(K</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">K)</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">type</span> <span class="pre">int)</span></code>) – A K,K integer matrix of count(label=k, true_label=k). Estimates a confident subset of
the joint distribution of the noisy and true labels P_{labels,y}.
Each entry in the matrix contains the number of examples confidently
counted into every pair (label=j, true_label=k) classes.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">An</span> <span class="pre">integer</span> <span class="pre">estimate</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">the</span> <span class="pre">number</span></code> of <code class="xref py py-class docutils literal notranslate"><span class="pre">label</span> <span class="pre">issues.</span></code></p>
</dd>
</dl>
</dd></dl>
</div>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          <a class="next-page" href="rank.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">rank</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="classification.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">classification</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    </body>
</html>