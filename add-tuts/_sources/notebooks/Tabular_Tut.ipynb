{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Tabular Data Classification with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use Cleanlab to find potential label errors in the German Credit dataset. This dataset contains 1,000 examples with 20 features, each example is labeled with either \"good\" or \"bad\" credit risk. Cleanlab will shortlist *hundreds* of examples that confuses our ML model the most; many of which are potential label errors, edge cases and obscure examples.\n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Build a simple classifier with scikit-learn's logistic regression.\n",
    "\n",
    "- Compute the out-of-sample predicted probabilities, `pyx`, with cross validation.\n",
    "\n",
    "- Generate a list of potential label errors with Cleanlab's `get_noise_indices`.\n",
    "\n",
    "- Build and train a robust model with Cleanlab's `LearningWithNoisyLabels` wrapper.\n",
    "\n",
    "**Data:** https://www.openml.org/d/31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Install the required dependencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``%%capture`` is a magic function to hide the cell's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install cleanlab sklearn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load the German Credit dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the data from OpenML then load the data's features in ``X_raw`` and its label in ``y_raw``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml('credit-g')\n",
    "X_raw = data.data\n",
    "y_raw = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Perform categorical encoding and feature scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform one-hot encoding on features with categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cat_features = X_raw.select_dtypes('category').columns\n",
    "X_encoded = pd.get_dummies(X_raw, columns=cat_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature scaling on features with numerical (float64) data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_features = X_raw.select_dtypes('float64').columns\n",
    "\n",
    "X_scaled = X_encoded.copy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled[num_features] = scaler.fit_transform(X_encoded[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform label encoding on the labels - \"bad\" is encoded as 0 and \"good\" is encoded as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_raw.map({'bad': 0, 'good': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Build a classification model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a scikit-learn Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Compute the out-of-sample predicted probabilities with cross validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit the entire dataset on the model used to compute the out-of-sample predicted probabilties, ``pyx``. This model will not be used for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the out-of-sample predicted probabilities, ``pyx``, with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "pyx = cross_val_predict(clf, X_scaled, y, cv=3, method='predict_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Run Cleanlab to find potential label errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.pruning import get_noise_indices\n",
    "\n",
    "ordered_label_errors = get_noise_indices(\n",
    "    s=y, psx=pyx, sorted_index_method=\"prob_given_label\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Review some of the highest potential label errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cleanlab found {len(ordered_label_errors)} potential label errors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top few potentially mislabeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.iloc[ordered_label_errors].assign(label=y_raw.iloc[ordered_label_errors]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Adapt with Cleanlab's wrapper and train a more robust model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the categorical encoded dataset into train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature scaling on features with numerical (float64) data type, this time fitting only on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new instance of scikit-learn's logistic regression classifier, then wrap it with Cleanlab's ``LearningWithNoisyLabels`` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels\n",
    "\n",
    "clf = LogisticRegression()\n",
    "lnl= LearningWithNoisyLabels(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the wrapped model, `lnl`, on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lnl.fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Evaluate the robust model's performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lnl.predict(X_test.to_numpy())\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What's next?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulation on completing this tutorial! Check out our following tutorial on using Cleanlab for audio classification, where we even found label errors in one of the most reputable audio datasets!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cda20062bc42cfdcaa0f9720c0b28e880bba110e9dfce6c1689934eec9b595a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
